{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9793f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model_classes_ import GCN_classification, GCN_regression\n",
    "from baseline_mdl_classes import MLP_classification, MLP_regression, CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3ceac",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c66523",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line = 'E116'\n",
    "max_epoch = 1000\n",
    "learning_rate = 1e-4\n",
    "num_graph_conv_layers = 2\n",
    "graph_conv_embed_size = 256\n",
    "num_lin_layers = 3\n",
    "lin_hidden_size = 256\n",
    "regression_flag = 0\n",
    "random_seed = 0\n",
    "\n",
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)\n",
    "num_classes = 2 if regression_flag == 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f2a95a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "save_dir = os.path.join(base_path, 'data', cell_line, 'saved_runs')\n",
    "hic_sparse_mat_file = os.path.join(base_path, 'data', cell_line, 'hic_sparse.npz')\n",
    "np_nodes_lab_genes_file = os.path.join(base_path, 'data',  cell_line, \\\n",
    "    'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')\n",
    "np_hmods_norm_all_file = os.path.join(base_path, 'data', cell_line, \\\n",
    "    'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "df_genes_file = os.path.join(base_path, 'data', cell_line, 'df_genes_reg' + str(regression_flag) + '.pkl')\n",
    "df_genes = pd.read_pickle(df_genes_file)\n",
    "\n",
    "mat = load_npz(hic_sparse_mat_file)\n",
    "allNodes_hms = np.load(np_hmods_norm_all_file)\n",
    "hms = allNodes_hms[:, 1:] #only includes features, not node ids\n",
    "X = torch.tensor(hms).float().reshape(-1, num_feat) \n",
    "allNodes = allNodes_hms[:, 0].astype(int)\n",
    "geneNodes_labs = np.load(np_nodes_lab_genes_file)\n",
    "\n",
    "geneNodes = geneNodes_labs[:, -2].astype(int)\n",
    "allLabs = -1*np.ones(np.shape(allNodes))\n",
    "\n",
    "targetNode_mask = torch.tensor(geneNodes).long()\n",
    "\n",
    "if regression_flag == 0:\n",
    "    geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "    allLabs[geneNodes] = geneLabs\n",
    "    Y = torch.tensor(allLabs).long()\n",
    "else:\n",
    "    geneLabs = geneNodes_labs[:, -1].astype(float)\n",
    "    allLabs[geneNodes] = geneLabs\n",
    "    Y = torch.tensor(allLabs).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d71254f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labs_counts = np.unique(allLabs, return_counts = True)\n",
    "plt.bar(x = labs_counts[0], height = labs_counts[1])\n",
    "plt.xticks(ticks=labs_counts[0])\n",
    "plt.title(\"Gene Presence and Distribution Activity in Data\")\n",
    "plt.xlabel(\"Gene Activity\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba99dc1",
   "metadata": {},
   "source": [
    "The plot above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2135c28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "for i in range(6):\n",
    "    axes[i].hist(X[:, i].numpy(), bins=20, alpha=0.7, color='blue')\n",
    "    axes[i].set_title(f'Histone Mark {i+1} Distribution')\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeb95b8",
   "metadata": {},
   "source": [
    "This plots..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029b702f",
   "metadata": {},
   "source": [
    "#### Helper Functions to train/evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57374c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_classification(model, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer):\n",
    "    '''\n",
    "    Trains model for classification task\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    max_epoch [int]: Maximum number of training epochs\n",
    "    learning_rate [float]: Learning rate\n",
    "    targetNode_mask [tensor]: Subgraph mask for training nodes\n",
    "    train_idx [array]: Node IDs corresponding to training set\n",
    "    valid_idx [array]: Node IDs corresponding to validation set\n",
    "    optimizer [PyTorch optimizer class]: PyTorch optimization algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss_vec [array]: Training loss for each epoch\n",
    "    train_AUROC_vec [array]: Training AUROC score for each epoch\n",
    "    valid_loss_vec [array]: Validation loss for each epoch\n",
    "    valid_AUROC_vec [array]: Validation AUROC score for each epoch\n",
    "\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        if e%100 == 0:\n",
    "            print(\"Epoch\", str(e), 'out of', str(max_epoch))\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### Only trains on nodes with genes due to masking\n",
    "        forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "        \n",
    "        train_scores = forward_scores[train_idx]\n",
    "\n",
    "        train_loss  = model.loss(train_scores, torch.LongTensor(train_labels).to(device))\n",
    "\n",
    "        train_softmax, _ = model.calc_softmax_pred(train_scores)\n",
    "\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        ### Calculate training and validation loss, AUROC scores\n",
    "        model.eval()\n",
    "        \n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss  = model.loss(valid_scores, torch.LongTensor(valid_labels).to(device))\n",
    "        valid_softmax, _ = model.calc_softmax_pred(valid_scores) \n",
    "\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        train_softmax = to_cpu_npy(train_softmax)\n",
    "        train_AUROC = roc_auc_score(train_labels, train_softmax[:,1], average=\"micro\")\n",
    "\n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        valid_softmax = to_cpu_npy(valid_softmax)\n",
    "        valid_AUROC = roc_auc_score(valid_labels, valid_softmax[:,1], average=\"micro\")\n",
    "        \n",
    "        train_AUROC_vec[e] = train_AUROC\n",
    "        valid_AUROC_vec[e] = valid_AUROC\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec\n",
    "\n",
    "\n",
    "def eval_model_classification(model, graph, targetNode_mask, train_idx, valid_idx, test_idx):\n",
    "    '''\n",
    "    Runs fully trained classification model and compute evaluation statistics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    targetNode_mask [tensor]: Mask ensuring model only trains on nodes with genes\n",
    "    train_idx [array]: Node IDs corresponding to training set;\n",
    "        analogous for valid_idx and test_idx\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_AUROC [float]: Test set AUROC score;\n",
    "        analogous for train_AUROC (training set) and valid_AUPR (validation set)\n",
    "    test_AUPR [float]: Test set AUPR score\n",
    "        analogous for train_AUPR (training set) and valid_AUPR (validation set)\n",
    "    test_pred [array]: Test set predictions;\n",
    "        analogous for train_pred (training set) and valid_pred (validation set)\n",
    "    test_labels [array]: Test set labels;\n",
    "        analagous for train_labels (training set) and valid_labels (validation set)\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "    test_labels = to_cpu_npy(graph.y[targetNode_mask[test_idx]])\n",
    "    \n",
    "    model.eval()\n",
    "    train_status=False\n",
    "\n",
    "    forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "\n",
    "    test_scores = forward_scores[test_idx]\n",
    "    test_softmax, test_pred = model.calc_softmax_pred(test_scores) \n",
    "    \n",
    "    test_softmax = to_cpu_npy(test_softmax)\n",
    "    test_pred = to_cpu_npy(test_pred)\n",
    "    test_AUROC = roc_auc_score(test_labels, test_softmax[:,1], average=\"micro\")\n",
    "    test_precision, test_recall, thresholds = precision_recall_curve(test_labels, test_softmax[:,1])\n",
    "    test_AUPR = auc(test_recall, test_precision)\n",
    "    # test_F1 = f1_score(test_labels, test_pred, average=\"micro\")\n",
    "    \n",
    "    train_scores = forward_scores[train_idx]\n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    train_softmax, train_pred = model.calc_softmax_pred(train_scores) \n",
    "    train_pred = to_cpu_npy(train_pred)\n",
    "    train_softmax = to_cpu_npy(train_softmax)\n",
    "    train_precision, train_recall, thresholds = precision_recall_curve(train_labels, train_softmax[:,1])\n",
    "    train_AUPR = auc(train_recall, train_precision)\n",
    "    # train_F1 = f1_score(train_labels, train_pred, average=\"micro\")\n",
    "\n",
    "    valid_scores = forward_scores[valid_idx]\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    valid_softmax, valid_pred = model.calc_softmax_pred(valid_scores) \n",
    "    valid_pred = to_cpu_npy(valid_pred)\n",
    "    valid_softmax = to_cpu_npy(valid_softmax)\n",
    "    valid_precision, valid_recall, thresholds = precision_recall_curve(valid_labels, valid_softmax[:,1])\n",
    "    valid_AUPR = auc(valid_recall, valid_precision)\n",
    "    # valid_F1 = f1_score(valid_labels, valid_pred, average=\"micro\")\n",
    "\n",
    "    return test_AUROC, test_AUPR, test_pred, test_labels, train_AUPR, train_pred, train_labels, \\\n",
    "        valid_AUPR, valid_pred, valid_labels\n",
    "\n",
    "\n",
    "def train_model_regression(model, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer):\n",
    "    '''\n",
    "    Trains model for regression task\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    max_epoch [int]: Maximum number of training epochs\n",
    "    learning_rate [float]: Learning rate\n",
    "    targetNode_mask [tensor]: Subgraph mask for training nodes\n",
    "    train_idx [array]: Node IDs corresponding to training set\n",
    "    valid_idx [array]: Node IDs corresponding to validation set\n",
    "    optimizer [PyTorch optimizer class]: PyTorch optimization algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss_vec [array]: Training loss for each epoch;\n",
    "        analagous for valid_loss_vec (validation set)\n",
    "    train_pearson_vec [array]: Training PCC for each epoch;\n",
    "        analogous for valid_pearson_vec (validation set)\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_pearson_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_pearson_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        if e%100 == 0:\n",
    "            print(\"Epoch\", str(e), 'out of', str(max_epoch))\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### Only trains on nodes with genes due to masking\n",
    "        forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "        \n",
    "        train_scores = forward_scores[train_idx]\n",
    "\n",
    "        train_loss  = model.loss(train_scores, torch.FloatTensor(train_labels).to(device))\n",
    "\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        ### Calculate training and validation loss, AUROC scores\n",
    "        model.eval()\n",
    "        \n",
    "        train_scores = to_cpu_npy(train_scores)\n",
    "        train_pearson = calc_pearson(train_scores, train_labels)\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        \n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss  = model.loss(valid_scores, torch.FloatTensor(valid_labels).to(device))\n",
    "        valid_scores = to_cpu_npy(valid_scores)\n",
    "        valid_pearson  = calc_pearson(valid_scores, valid_labels)\n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        \n",
    "        train_pearson_vec[e] = train_pearson\n",
    "        valid_pearson_vec[e] = valid_pearson\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec\n",
    "\n",
    "\n",
    "def eval_model_regression(model, graph, targetNode_mask, train_idx, valid_idx, test_idx):\n",
    "    '''\n",
    "    Runs fully trained regression model and compute evaluation statistics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    targetNode_mask [tensor]: Mask ensuring model only trains on nodes with genes\n",
    "    train_idx [array]: Node IDs corresponding to training set;\n",
    "        analogous for valid_idx and test_idx\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_pearson [float]: PCC for test set;\n",
    "        analogous for train_pearson (training set) and valid_pearson (validation set)\n",
    "    test_pred [array]: Test set predictions;\n",
    "        analogous for train_pred (training set) and valid_pred (validation set)\n",
    "    test_labels [array]: Test set labels (expression values);\n",
    "        analagous for train_labels (training set) and valid_labels (validation set)\n",
    "\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    train_status=False\n",
    "\n",
    "    forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "\n",
    "    test_scores = forward_scores[test_idx]\n",
    "    test_pred = to_cpu_npy(test_scores)\n",
    "    test_labels = to_cpu_npy(graph.y[targetNode_mask[test_idx]])\n",
    "    test_pearson = calc_pearson(test_pred, test_labels)\n",
    "\n",
    "    train_scores = forward_scores[train_idx]\n",
    "    train_pred = to_cpu_npy(train_scores)\n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    train_pearson = calc_pearson(train_pred, train_labels)\n",
    "\n",
    "    valid_scores = forward_scores[valid_idx]\n",
    "    valid_pred = to_cpu_npy(valid_scores)\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    valid_pearson = calc_pearson(valid_pred, valid_labels)\n",
    "\n",
    "    return test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "        valid_pearson, valid_pred, valid_labels\n",
    "        \n",
    "\n",
    "def calc_pearson(scores, targets):\n",
    "    '''\n",
    "    Calculates Pearson correlation coefficient (PCC) between predicted \\\n",
    "        expression levels and true expression levels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores [array]: Predicted expression levels\n",
    "    targets [array]: True expression levels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pcc [float]: Pearson correlation coefficient\n",
    "\n",
    "    '''\n",
    "    pcc, _ = pearsonr(scores, targets)\n",
    "            \n",
    "    return pcc\n",
    "    \n",
    "    \n",
    "def to_cpu_npy(x):\n",
    "    '''\n",
    "    Simple helper function to transfer GPU tensors to CPU numpy matrices\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x [tensor]: PyTorch tensor stored on GPU\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_x [array]: Numpy array stored on CPU\n",
    "\n",
    "    '''\n",
    "\n",
    "    new_x = x.cpu().detach().numpy()\n",
    "    \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d22007",
   "metadata": {},
   "source": [
    "# GC-MERGE Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c5fc6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter and model definitions\n",
    "cell_line = 'E116'\n",
    "max_epoch = 1000\n",
    "learning_rate = 1e-4\n",
    "num_graph_conv_layers = 2\n",
    "graph_conv_embed_size = 256\n",
    "num_lin_layers = 3\n",
    "lin_hidden_size = 256\n",
    "regression_flag = 0\n",
    "random_seed = 0\n",
    "\n",
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)\n",
    "num_classes = 2 if regression_flag == 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a901594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell line: E116\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.0001\n",
      "Number of graph convolutional layers: 2\n",
      "Graph convolutional embedding size: 256\n",
      "Number of linear layers: 3\n",
      "Linear hidden layer size: 256\n"
     ]
    }
   ],
   "source": [
    "print('Cell line:', cell_line)\n",
    "print('ChIP-seq resolution:', str(chip_res))\n",
    "print('\\n')\n",
    "print('Training set: 70%')\n",
    "print('Validation set: 15%')\n",
    "print('Testing set: 15%')\n",
    "print('\\n')\n",
    "print('Model hyperparameters: ')\n",
    "print('Number of epochs:', max_epoch)\n",
    "print('Learning rate:', learning_rate)\n",
    "print('Number of graph convolutional layers:', str(num_graph_conv_layers))\n",
    "print('Graph convolutional embedding size:', graph_conv_embed_size)\n",
    "print('Number of linear layers:', str(num_lin_layers))\n",
    "print('Linear hidden layer size:', lin_hidden_size)\n",
    "\n",
    "# random_seed = random.randint(0,10000)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "###Test for GPU availability\n",
    "cuda_flag = torch.cuda.is_available()\n",
    "if cuda_flag:  \n",
    "  dev = \"cuda\" \n",
    "else:\n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77c9db",
   "metadata": {},
   "source": [
    "Created Function to reuse data preparation steps over mulitple runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de58b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Load input files\n",
    "def prepare_data(cell_line, regression_flag):\n",
    "    base_path = os.getcwd()\n",
    "    save_dir = os.path.join(base_path, 'data', cell_line, 'saved_runs')\n",
    "    hic_sparse_mat_file = os.path.join(base_path, 'data', cell_line, 'hic_sparse.npz')\n",
    "    np_nodes_lab_genes_file = os.path.join(base_path, 'data',  cell_line, \\\n",
    "        'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')\n",
    "    np_hmods_norm_all_file = os.path.join(base_path, 'data', cell_line, \\\n",
    "        'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "    df_genes_file = os.path.join(base_path, 'data', cell_line, 'df_genes_reg' + str(regression_flag) + '.pkl')\n",
    "    df_genes = pd.read_pickle(df_genes_file)\n",
    "    \n",
    "    mat = load_npz(hic_sparse_mat_file)\n",
    "    allNodes_hms = np.load(np_hmods_norm_all_file)\n",
    "    hms = allNodes_hms[:, 1:] #only includes features, not node ids\n",
    "    X = torch.tensor(hms).float().reshape(-1, num_feat) \n",
    "    allNodes = allNodes_hms[:, 0].astype(int)\n",
    "    geneNodes_labs = np.load(np_nodes_lab_genes_file)\n",
    "\n",
    "    geneNodes = geneNodes_labs[:, -2].astype(int)\n",
    "    allLabs = -1*np.ones(np.shape(allNodes))\n",
    "\n",
    "    targetNode_mask = torch.tensor(geneNodes).long()\n",
    "\n",
    "    if regression_flag == 0:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "        allLabs[geneNodes] = geneLabs\n",
    "        Y = torch.tensor(allLabs).long()\n",
    "    else:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(float)\n",
    "        allLabs[geneNodes] = geneLabs\n",
    "        Y = torch.tensor(allLabs).float()\n",
    "\n",
    "    extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "    data = torch_geometric.data.Data(edge_index = extract[0], edge_attr = extract[1], x = X, y = Y)\n",
    "    G = data\n",
    "    \n",
    "    ###Randomize node order and split into 70%/15%/15% training/validation/test sets\n",
    "    pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "    fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "    fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "    train_idx = pred_idx_shuff[:fin_train]\n",
    "    valid_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "    test_idx = pred_idx_shuff[fin_valid:]\n",
    "    \n",
    "    return G, targetNode_mask, train_idx, valid_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe17d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_conv_embed_size = 256\n",
    "num_graph_conv_layers = 2\n",
    "\n",
    "graph_conv_layer_sizes = [num_feat] + \\\n",
    "    [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "          for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "\n",
    "graph_lin_hidden_sizes = [graph_conv_layer_sizes[-1]] + \\\n",
    "    [int(max(lin_hidden_size, num_classes)) \\\n",
    "          for i in np.arange(1, num_lin_layers, 1)] + [num_classes]\n",
    "\n",
    "graph_lin_hidden_sizes_reg = [graph_conv_layer_sizes[-1]] + \\\n",
    "    [int(max(lin_hidden_size, num_classes)) \\\n",
    "          for i in np.arange(1, num_lin_layers, 1)] + [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad78452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 256, 256, 2]\n"
     ]
    }
   ],
   "source": [
    "num_classes_reg = 1\n",
    "lin_hidden_sizes = [num_feat] + [int(max(lin_hidden_size, num_classes)) for i in np.arange(1, num_lin_layers, 1)] + [num_classes]\n",
    "lin_hidden_sizes_reg = [num_feat] + [int(max(lin_hidden_size, num_classes_reg)) for i in np.arange(1, num_lin_layers, 1)] + [num_classes_reg]\n",
    "\n",
    "print(lin_hidden_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5426a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_lines = ['E116', 'E122', 'E123']\n",
    "classification_res = pd.DataFrame(columns=cell_lines)\n",
    "regression_res = pd.DataFrame(columns=cell_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89782f9a",
   "metadata": {},
   "source": [
    "In the cell below, we are training GC-MERGE Classifier on three different cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee78331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cell Line E116...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "\n",
      "Training Cell Line E122...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "\n",
      "Training Cell Line E123...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E116</th>\n",
       "      <th>E122</th>\n",
       "      <th>E123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.920619</td>\n",
       "      <td>0.895129</td>\n",
       "      <td>0.930426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         E116      E122      E123\n",
       "GCN  0.920619  0.895129  0.930426"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_auroc = []\n",
    "for cell_line in cell_lines:\n",
    "    print(f'\\nTraining Cell Line {cell_line}...')\n",
    "    G, targetNode_mask, train_idx, valid_idx, test_idx = prepare_data(cell_line=cell_line, regression_flag = regression_flag)\n",
    "    \n",
    "    model = GCN_classification(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, graph_lin_hidden_sizes, num_classes)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    \n",
    "    train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec = \\\n",
    "    train_model_classification(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "\n",
    "    test_AUROC, test_AUPR, test_pred, test_labels, train_AUPR, train_pred, train_labels, \\\n",
    "        valid_AUPR, valid_pred, valid_labels = \\\n",
    "            eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "    \n",
    "    gcn_auroc.append(test_AUROC)\n",
    "    \n",
    "classification_res.loc['GCN'] = gcn_auroc\n",
    "classification_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c7333",
   "metadata": {},
   "source": [
    "In the cell below, we run GC-MERGE Regressor for the 3 cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13a22ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cell Line E116...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "\n",
      "Training Cell Line E122...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "\n",
      "Training Cell Line E123...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E116</th>\n",
       "      <th>E122</th>\n",
       "      <th>E123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.769753</td>\n",
       "      <td>0.761256</td>\n",
       "      <td>0.803726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         E116      E122      E123\n",
       "GCN  0.769753  0.761256  0.803726"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes_reg = 1\n",
    "\n",
    "gcn_pearson = []\n",
    "for cell_line in cell_lines:\n",
    "    print(f'\\nTraining Cell Line {cell_line}...')\n",
    "    G, targetNode_mask, train_idx, valid_idx, test_idx = prepare_data(cell_line=cell_line, regression_flag = 1)\n",
    "    \n",
    "    model = GCN_regression(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, graph_lin_hidden_sizes_reg, num_classes_reg)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    \n",
    "    train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec = \\\n",
    "        train_model_regression(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "    \n",
    "    test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "        valid_pearson, valid_pred, valid_labels = \\\n",
    "            eval_model_regression(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "    \n",
    "    gcn_pearson.append(test_pearson)\n",
    "    \n",
    "regression_res.loc['GCN'] = gcn_pearson\n",
    "regression_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071716f",
   "metadata": {},
   "source": [
    "# MLP Runs\n",
    "\n",
    "Code for defining the models can be found in baseline_mdl_classes.py. For MLP, we used the same architecture for the network as GC-MERGE, but removed the GraphSAGE layers. This eliminated the graph feature of the model and skipped to running the node features through a fully connected network to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d40807",
   "metadata": {},
   "source": [
    "In the cell below, we run the baseline MLP Classifier model on three cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c40b3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cell Line E116...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "\n",
      "Training Cell Line E122...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "\n",
      "Training Cell Line E123...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E116</th>\n",
       "      <th>E122</th>\n",
       "      <th>E123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.920619</td>\n",
       "      <td>0.895129</td>\n",
       "      <td>0.930426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.900210</td>\n",
       "      <td>0.893430</td>\n",
       "      <td>0.916839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         E116      E122      E123\n",
       "GCN  0.920619  0.895129  0.930426\n",
       "MLP  0.900210  0.893430  0.916839"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_auroc = []\n",
    "\n",
    "for cell_line in ['E116', 'E122', 'E123']:\n",
    "    print(f'\\nTraining Cell Line {cell_line}...')\n",
    "    G, targetNode_mask, train_idx, valid_idx, test_idx = prepare_data(cell_line=cell_line, regression_flag = regression_flag)\n",
    "    \n",
    "    model = MLP_classification(num_feat, num_lin_layers, lin_hidden_sizes, num_classes)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    \n",
    "    train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec = \\\n",
    "    train_model_classification(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "\n",
    "    test_AUROC, test_AUPR, test_pred, test_labels, train_AUPR, train_pred, train_labels, \\\n",
    "        valid_AUPR, valid_pred, valid_labels = \\\n",
    "            eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "    \n",
    "    mlp_auroc.append(test_AUROC)\n",
    "    \n",
    "classification_res.loc['MLP'] = mlp_auroc\n",
    "classification_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6593575",
   "metadata": {},
   "source": [
    "In the cell below, we ran the baseline MLP Regressor on 3 cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "321b64e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cell Line E116...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "\n",
      "Training Cell Line E122...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "\n",
      "Training Cell Line E123...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E116</th>\n",
       "      <th>E122</th>\n",
       "      <th>E123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.769753</td>\n",
       "      <td>0.761256</td>\n",
       "      <td>0.803726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.771698</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.797430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         E116      E122      E123\n",
       "GCN  0.769753  0.761256  0.803726\n",
       "MLP  0.771698  0.728571  0.797430"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pearson = []\n",
    "\n",
    "for cell_line in ['E116', 'E122', 'E123']:\n",
    "    print(f'\\nTraining Cell Line {cell_line}...')\n",
    "    G, targetNode_mask, train_idx, valid_idx, test_idx = prepare_data(cell_line=cell_line, regression_flag = 1)\n",
    "    \n",
    "    model = MLP_regression(num_feat, num_lin_layers, lin_hidden_sizes_reg, num_classes_reg)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    \n",
    "    train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec = \\\n",
    "        train_model_regression(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "    \n",
    "    test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "        valid_pearson, valid_pred, valid_labels = \\\n",
    "            eval_model_regression(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "    \n",
    "    mlp_pearson.append(test_pearson)\n",
    "    \n",
    "regression_res.loc['MLP'] = mlp_pearson\n",
    "regression_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de501f7",
   "metadata": {},
   "source": [
    "# CNN Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "874a476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "train_idx = pred_idx_shuff[:fin_train]\n",
    "valid_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "test_idx = pred_idx_shuff[fin_valid:]\n",
    "\n",
    "train_data = X[targetNode_mask][train_idx]\n",
    "train_labels = torch.tensor(geneNodes_labs[train_idx][:, 1]).long()\n",
    "\n",
    "valid_data = X[targetNode_mask][valid_idx]\n",
    "valid_labels = torch.tensor(geneNodes_labs[valid_idx][:, 1]).long()\n",
    "\n",
    "test_data = X[targetNode_mask][test_idx]\n",
    "test_labels = torch.tensor(geneNodes_labs[test_idx][:, 1]).long()\n",
    "\n",
    "train_data = train_data.unsqueeze(1)\n",
    "test_data = test_data.unsqueeze(1)\n",
    "valid_data = valid_data.unsqueeze(1)\n",
    "\n",
    "INPUT_LENGTH = 6\n",
    "NUM_CLASSES = 2 \n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9383da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(valid_data, valid_labels)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_data, valid_labels)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5980c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(valid_data, valid_labels)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_data, valid_labels)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2f023e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1667/4206092366.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(model, n_epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epochs = 100\n",
    "    valid_accuracies = []\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_inputs, batch_labels in train_data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(batch_inputs)\n",
    "            loss = criterion(output, batch_labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_data_loader)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            valid_accuracy = model.calculate_accuracy(valid_dataset)\n",
    "            valid_accuracies.append(valid_accuracy)\n",
    "            print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {avg_loss:.4f}, Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if len(valid_accuracies) > 2:\n",
    "            if (valid_accuracies[-1] < valid_accuracies[-2]) and (valid_accuracies[-1] < valid_accuracies[-3]):\n",
    "                print(f'Training stopped due to early stopping at epoch {epoch}')\n",
    "                break\n",
    "\n",
    "    return valid_accuracies[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3d99f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(num_conv_layers=3, num_linear_layers=2, dropout_rate=0).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001).to(device)\n",
    "\n",
    "train(model, n_epochs=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7deda5",
   "metadata": {},
   "source": [
    "Grid Search For hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_conv_layers = [1, 2, 3]\n",
    "num_linear_layers = [1, 2, 3]\n",
    "dropout_rates = [0, 0.1, 0.2, 0.3]\n",
    "\n",
    "results_df = pd.DataFrame(columns=['num_conv_layers', 'num_linear_layers', 'dropout_rate', 'validation_accuracy'])\n",
    "\n",
    "for num_conv in num_conv_layers:\n",
    "    for num_linear in num_linear_layers:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = CNN(num_conv_layers=num_conv, num_linear_layers=num_linear, dropout_rate=dropout_rate)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "            valid_accuracy = train(model, n_epochs=200)\n",
    "            results_df.loc[len(results_df)] = [num_conv, num_linear, dropout_rate, valid_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af17a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d67059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3914f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79cd282d",
   "metadata": {},
   "source": [
    "#### Question From Midterm Report:\n",
    "\n",
    "**3:** Let’s say your training a model and the accuracy for the model plateaued after the first epoch. I.e. the accuracy remains the same for every epoch. List 5 factors that could cause this and how you would address each of them.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. Check the learning rate. If the learning rate is too high, training could converge quickly and plateau after the first epoch. It also could have quickly found a local minimum, so the best solution is not found. A learning rate that is too low would not be a likely cause of this issue, as training would converge slower, not faster. If a low learning rate still causes the training to plateau, another issue is likely the cause.\n",
    "\n",
    "2. Check the distribution of classes. If the model is a classification model, the classes could be imbalanced. For example, 94% of data could be in one class, and the remaining 6% could be scattered across 5 other classes. This would cause the training to only be able to detect some patterns from the data, or cause it to only predict the class containing 94% of the data every time. Therefore, learning doesn't improve, and it plateaus after the first epoch. This can be fixed by oversampling the minority classes or undersampling the majority class to create a more even distribution for training. Another option is to weigh the minority classes much higher than the majority class in training.\n",
    "\n",
    "3. Check the batch size. If the batch size is really small, training accuracy could increase quickly and stop. If the batch size is too large, it could overfit. Finding the right batch size through hyperparameter tuning would ensure both issues don't occur.\n",
    "\n",
    "4. Check if the model is too large. If the model is too large (and/or the learning rate is too high), it could cause training to plateau early. Using regularization such as dropout, L1, or L2 could help reduce the complexity of the model to the point where training doesn't plateau after 1 epoch.\n",
    "\n",
    "5. Check the model parameters. Perhaps the choices of parameters such as number of layers, input size, output size, or hidden dimension size are not optimal for the model. Using grid search or other hyperparameter tuning methods to find optimal values for each of these could help the training stagnation issue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
