{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b3fcce-7f42-433e-a92c-f0e760c34e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.conv import GATConv\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1ebb1f-8bd1-4e50-89f7-6c36c3da41b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69a1732-2163-4b4e-8ac2-57be8e58bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line = 'E116'\n",
    "regression_flag = 0\n",
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)\n",
    "num_classes = 2 if regression_flag == 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0cbfc0d-9684-4d1b-abe3-cd6d5976bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data paths\n",
    "src_dir = os.getcwd()\n",
    "#src_dir = os.path.dirname(base_path)\n",
    "save_dir = os.path.join(src_dir, 'data', cell_line, 'saved_runs')\n",
    "hic_sparse_mat_file = os.path.join(src_dir, 'data', cell_line, 'hic_sparse.npz')\n",
    "np_nodes_lab_genes_file = os.path.join(src_dir, 'data',  cell_line, \\\n",
    "    'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')\n",
    "np_hmods_norm_all_file = os.path.join(src_dir, 'data', cell_line, \\\n",
    "    'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "df_genes_file = os.path.join(src_dir, 'data', cell_line, 'df_genes_reg' + str(regression_flag) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43a6d81-7348-4e30-ac42-18b2df594814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_catalog_name</th>\n",
       "      <th>abbrev</th>\n",
       "      <th>hic_node_id</th>\n",
       "      <th>expression_lvl</th>\n",
       "      <th>connected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000237613</td>\n",
       "      <td>FAM138A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000186092</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000235249</td>\n",
       "      <td>OR4F29</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000185097</td>\n",
       "      <td>OR4F16</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000197049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>ENSG00000100288</td>\n",
       "      <td>CHKB</td>\n",
       "      <td>279585</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>ENSG00000100299</td>\n",
       "      <td>ARSA</td>\n",
       "      <td>279588</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>ENSG00000251322</td>\n",
       "      <td>SHANK3</td>\n",
       "      <td>279593</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>ENSG00000100312</td>\n",
       "      <td>ACR</td>\n",
       "      <td>279599</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>ENSG00000079974</td>\n",
       "      <td>RABL2B</td>\n",
       "      <td>279604</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16699 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gene_catalog_name   abbrev  hic_node_id  expression_lvl  connected\n",
       "0     ENSG00000237613  FAM138A            3               0        1.0\n",
       "1     ENSG00000186092    OR4F5            6               0        1.0\n",
       "2     ENSG00000235249   OR4F29           36               0        1.0\n",
       "3     ENSG00000185097   OR4F16           62               0        1.0\n",
       "4     ENSG00000197049      NaN           72               1        1.0\n",
       "..                ...      ...          ...             ...        ...\n",
       "384   ENSG00000100288     CHKB       279585               0        1.0\n",
       "385   ENSG00000100299     ARSA       279588               1        1.0\n",
       "386   ENSG00000251322   SHANK3       279593               0        1.0\n",
       "387   ENSG00000100312      ACR       279599               0        1.0\n",
       "388   ENSG00000079974   RABL2B       279604               1        1.0\n",
       "\n",
       "[16699 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genes = pd.read_pickle(df_genes_file)\n",
    "df_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86eb4689-f8ee-4efa-a5f7-e80671fbf564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.97% of all regions encode genes\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_expressed?</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62.0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72.0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gene_expressed?\n",
       "gene_id                 \n",
       "3.0                  0.0\n",
       "6.0                  0.0\n",
       "36.0                 0.0\n",
       "62.0                 0.0\n",
       "72.0                 1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = load_npz(hic_sparse_mat_file)\n",
    "allNodes_hms = np.load(np_hmods_norm_all_file) #contains 6 histone marks for all 279606 regions + id (Shape = [279606, 7])\n",
    "hms = allNodes_hms[:, 1:] #only includes features, not node ids (Shape = [279606, 6])\n",
    "X = torch.tensor(hms).float().reshape(-1, num_feat) #convert hms to tensor (Shape = [279606, 6])\n",
    "allNodes = allNodes_hms[:, 0].astype(int) #contains ids of all regions (Shape = [279606, 1])\n",
    "\n",
    "\n",
    "geneNodes_labs = np.load(np_nodes_lab_genes_file) #contains the expression level of each gene (Shape = [16699, 2])\n",
    "\n",
    "#Dataframe only contains regions that encode a gene\n",
    "print(f'{(geneNodes_labs.shape[0] * 100 / X.shape[0]):.2f}% of all regions encode genes\\n')\n",
    "pd.DataFrame(geneNodes_labs, columns=['gene_id', 'gene_expressed?']).set_index('gene_id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20261f15-a589-4d39-b9b7-cbcd9cb8680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geneNodes = geneNodes_labs[:, -2].astype(int) #contains ids of regions that encode a gene (Shape = [16699, 1])\n",
    "\n",
    "allLabs = -1*np.ones(np.shape(allNodes))\n",
    "targetNode_mask = torch.tensor(geneNodes).long()\n",
    "geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "allLabs[geneNodes] = geneLabs #contains expression level for each region (-1 if region doesn't encode gene, 1 if gene is expressed, 0 if not)\n",
    "Y = torch.tensor(allLabs).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e437305-6062-4960-bde9-09ebadd630fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[     0,      1,      1,  ..., 279605, 279605, 279605],\n",
       "         [  8765,     24,     67,  ..., 279595, 279598, 279599]]),\n",
       " tensor([168.5447,  66.0712,  15.8497,  ...,  38.9206,  59.0113, 120.2268],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "\n",
    "#extract[0] (Shape = [2, 3906914]) contains nodes that have edges between them --> (extract[0][0][0], extract[0][1][0]) is an edge\n",
    "#extract[1] (Shape = [1, 3906914]) contain the HI-C edge weights\n",
    "extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4e5e8c-c63a-4dcb-ad31-46c94617d66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[279606, 6], edge_index=[2, 3906914], edge_attr=[3906914], y=[279606])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define graph with nodes, node features, edges, and edge features\n",
    "\n",
    "data = torch_geometric.data.Data(edge_index = extract[0], edge_attr = extract[1], x = X, y = Y)\n",
    "G = data\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e50c8e8b-c49b-42c7-99dd-a489e8382422",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "train_idx = pred_idx_shuff[:fin_train]\n",
    "valid_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "test_idx = pred_idx_shuff[fin_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b0951d8-3373-485a-bd11-82e5481b692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cpu_npy(x):\n",
    "    return x.cpu().detach().numpy()\n",
    "    \n",
    "def train_model_classification(model, loss, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer):\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    \n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for e in list(range(max_epoch)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        all_scores = model(graph)[targetNode_mask]\n",
    "        train_scores = all_scores[train_idx]\n",
    "        \n",
    "        train_loss = loss(train_scores, torch.LongTensor(train_labels).to(device))\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        valid_scores = all_scores[valid_idx]\n",
    "        valid_loss = loss(valid_scores, torch.LongTensor(valid_labels).to(device))\n",
    "        valid_losses.append(valid_loss.item())\n",
    "\n",
    "        if e%100 == 0:\n",
    "            print(f'Epoch {e}: Train Loss = {train_loss}, Valid Loss = {valid_loss}')\n",
    "\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66559214-df58-4e43-b542-80229ea55a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_heads=3):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels[0], heads=num_heads, concat=True)\n",
    "        self.gat2 = GATConv(hidden_channels[0] * num_heads, hidden_channels[1], heads=num_heads, concat=False)\n",
    "        #self.gat3 = GATConv(hidden_channels[1] * num_heads, hidden_channels[2], heads=num_heads, concat=False)\n",
    "        \n",
    "        self.ff1 = nn.Linear(hidden_channels[-1], hidden_channels[-1] // 2)\n",
    "        self.ff2 = nn.Linear(hidden_channels[-1] // 2, 2)\n",
    "        self.dropout = nn.Dropout(p=0.15)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = torch.relu(self.gat1(x, edge_index, edge_attr))\n",
    "        x = torch.relu(self.gat2(x, edge_index, edge_attr))\n",
    "        #x = torch.relu(self.gat3(x, edge_index, edge_attr))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.ff1(x))\n",
    "        x = self.ff2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51f1623a-b2c0-44c1-8155-3013d88d98ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.710981547832489, Valid Loss = 0.7131888270378113\n",
      "Epoch 100: Train Loss = 0.5335248112678528, Valid Loss = 0.5427634119987488\n",
      "Epoch 200: Train Loss = 0.5053207278251648, Valid Loss = 0.5126533508300781\n",
      "Epoch 300: Train Loss = 0.47209662199020386, Valid Loss = 0.47558701038360596\n",
      "Epoch 400: Train Loss = 0.4548182487487793, Valid Loss = 0.45644092559814453\n",
      "Epoch 500: Train Loss = 0.4427942633628845, Valid Loss = 0.44046857953071594\n",
      "Epoch 600: Train Loss = 0.4356141984462738, Valid Loss = 0.4335882067680359\n",
      "Epoch 700: Train Loss = 0.42922353744506836, Valid Loss = 0.429802268743515\n",
      "Epoch 800: Train Loss = 0.42323583364486694, Valid Loss = 0.42417439818382263\n",
      "Epoch 900: Train Loss = 0.4190025329589844, Valid Loss = 0.4214588403701782\n",
      "Epoch 1000: Train Loss = 0.41593241691589355, Valid Loss = 0.42285409569740295\n",
      "Epoch 1100: Train Loss = 0.41125035285949707, Valid Loss = 0.41850370168685913\n",
      "Epoch 1200: Train Loss = 0.40875911712646484, Valid Loss = 0.4159849286079407\n",
      "Epoch 1300: Train Loss = 0.4051287770271301, Valid Loss = 0.41475388407707214\n",
      "Epoch 1400: Train Loss = 0.4013560712337494, Valid Loss = 0.41737067699432373\n",
      "Epoch 1500: Train Loss = 0.39948126673698425, Valid Loss = 0.41644522547721863\n",
      "Epoch 1600: Train Loss = 0.39587464928627014, Valid Loss = 0.4188579022884369\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m gat \u001b[38;5;241m=\u001b[39m GAT(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, hidden_channels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m45\u001b[39m])\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m p : p\u001b[38;5;241m.\u001b[39mrequires_grad, gat\u001b[38;5;241m.\u001b[39mparameters()), lr \u001b[38;5;241m=\u001b[39m learning_rate)\n\u001b[0;32m----> 8\u001b[0m train_losses, valid_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetNode_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m, in \u001b[0;36mtrain_model_classification\u001b[0;34m(model, loss, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\u001b[0m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     34\u001b[0m valid_scores \u001b[38;5;241m=\u001b[39m all_scores[valid_idx]\n\u001b[0;32m---> 35\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m loss(valid_scores, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     36\u001b[0m valid_losses\u001b[38;5;241m.\u001b[39mappend(valid_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "max_epoch = 2000\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "gat = GAT(in_channels=6, hidden_channels=[10, 45])\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, gat.parameters()), lr = learning_rate)\n",
    "\n",
    "train_losses, valid_losses = train_model_classification(gat, loss, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b9d4f7-7ab3-41de-85bc-7a4e09036177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
