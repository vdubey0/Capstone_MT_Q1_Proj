{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e447bbca-bd5d-4a29-b6bc-067da0204b9b",
   "metadata": {},
   "source": [
    "# Model Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b2462-851a-467e-9c72-50d21120a247",
   "metadata": {},
   "source": [
    "### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef160cd-b3ca-45b7-b73f-0e6d26299fa9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# importing torch packages\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import OptPairTensor, Adj, Size\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.conv import GATConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "# importing utility packages\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "from typing import Union, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing evaluation packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve, auc\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# importing training/eval functions\n",
    "from training_eval import train_model_classification, eval_model_classification, train_model_regression, eval_model_regression\n",
    "\n",
    "# importing models\n",
    "from final_model_classes.gcn_model import GCN_classification, GCN_regression\n",
    "from final_model_classes.mlp_model import MLP_classification, MLP_regression\n",
    "from final_model_classes.cnn_model import CNN\n",
    "from final_model_classes.weighted_gcn_model import GCN_classification_weighted\n",
    "from final_model_classes.gat_model import GAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a71362-2bca-43d3-bb25-7a41eba89c7f",
   "metadata": {},
   "source": [
    "### Setting torch device (CAUTION: Make sure one GPU is available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80fea983-4c8f-43bb-93fb-049bed179547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4a922-3039-4df2-8114-6ab1983f5680",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56c1dd8-2e49-4b8a-b9a1-f57609780d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cpu_npy(x):\n",
    "    return x.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35361f2a-73f1-4f0f-9fdf-c5874189799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pearson(predictions, labels):\n",
    "    return pearsonr(predictions, labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c790080-d78b-4e7b-a3b0-530ea61cf4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(cell_line, regression_flag, base_path):\n",
    "    save_dir = os.path.join(base_path, 'data', cell_line, 'saved_runs')\n",
    "    \n",
    "    hic_sparse_mat_file = os.path.join(base_path, 'data', cell_line, 'hic_sparse.npz')\n",
    "    np_nodes_lab_genes_file = os.path.join(base_path, 'data',  cell_line, \\\n",
    "        'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')\n",
    "    np_hmods_norm_all_file = os.path.join(base_path, 'data', cell_line, \\\n",
    "        'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "    df_genes_file = os.path.join(base_path, 'data', cell_line, 'df_genes_reg' + str(regression_flag) + '.pkl')\n",
    "    df_genes = pd.read_pickle(df_genes_file)\n",
    "    \n",
    "    mat = load_npz(hic_sparse_mat_file)\n",
    "    allNodes_hms = np.load(np_hmods_norm_all_file) #contains 6 histone marks for all 279606 regions + id (Shape = [279606, 7])\n",
    "    hms = allNodes_hms[:, 1:] #only includes features, not node ids (Shape = [279606, 6])\n",
    "    X = torch.tensor(hms).float().reshape(-1, num_feat) #convert hms to tensor (Shape = [279606, 6])\n",
    "    allNodes = allNodes_hms[:, 0].astype(int) #contains ids of all regions (Shape = [279606, 1])\n",
    "    geneNodes_labs = np.load(np_nodes_lab_genes_file)  #contains the expression level of each gene (Shape = [16699, 2])\n",
    "\n",
    "    geneNodes = geneNodes_labs[:, -2].astype(int)  #contains ids of regions that encode a gene (Shape = [16699, 1])\n",
    "    allLabs = -1*np.ones(np.shape(allNodes))\n",
    "\n",
    "    targetNode_mask = torch.tensor(geneNodes).long()\n",
    "\n",
    "    if regression_flag == 0:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "        allLabs[geneNodes] = geneLabs #contains expression level for each region (-1 if region doesn't encode gene, 1 if gene is expressed, 0 if not)\n",
    "        Y = torch.tensor(allLabs).long()\n",
    "    else:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(float)\n",
    "        allLabs[geneNodes] = geneLabs #contains expression level for each region (-1 if region doesn't encode gene, 1 if gene is expressed, 0 if not)\n",
    "        Y = torch.tensor(allLabs).float()\n",
    "\n",
    "    extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "    data = torch_geometric.data.Data(edge_index = extract[0], edge_attr = extract[1], x = X, y = Y)\n",
    "    G = data\n",
    "    \n",
    "    ###Randomize node order and split into 70%/15%/15% training/validation/test sets\n",
    "    torch.manual_seed(0)\n",
    "    pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "    fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "    fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "    \n",
    "    return G, targetNode_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84827a-ebca-4ca0-b1c9-0c84d75460a4",
   "metadata": {},
   "source": [
    "### Setting Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ea3534-8368-4a14-8090-2cbe0a0ccbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_lines = ['E116', 'E122', 'E123']\n",
    "regression_flag = 0\n",
    "current_dir = os.getcwd()\n",
    "src_dir = os.path.dirname(current_dir)\n",
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)\n",
    "lin_hidden_size = 256\n",
    "learning_rate = 1e-4\n",
    "\n",
    "GAT_hidden_channels=[6, 30]\n",
    "GAT_dropout = 0.5\n",
    "GAT_wd = 1e-05\n",
    "GAT_num_heads = 4\n",
    "GAT_lr = 0.002\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "max_epoch = 1000\n",
    "max_epoch_weighted_agg = 1500 # increasing epochs due to the increase in model parameters\n",
    "\n",
    "num_graph_conv_layers = 2\n",
    "graph_conv_embed_size = 256\n",
    "num_classes = 2 if regression_flag == 0 else 1\n",
    "\n",
    "num_lin_layers = 3\n",
    "graph_conv_layer_sizes = [num_feat] + \\\n",
    "    [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "          for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "\n",
    "graph_lin_hidden_sizes = [graph_conv_layer_sizes[-1]] + \\\n",
    "    [int(max(lin_hidden_size, num_classes)) \\\n",
    "          for i in np.arange(1, num_lin_layers, 1)] + [num_classes]\n",
    "\n",
    "lin_hidden_sizes = [num_feat] + [int(max(lin_hidden_size, num_classes)) for i in np.arange(1, num_lin_layers, 1)] + [num_classes]\n",
    "\n",
    "num_classes_reg = 1\n",
    "\n",
    "lin_hidden_sizes_reg = [num_feat] + [int(max(lin_hidden_size, num_classes_reg)) for i in np.arange(1, num_lin_layers, 1)] + [num_classes_reg]\n",
    "\n",
    "graph_lin_hidden_sizes_reg = [graph_conv_layer_sizes[-1]] + \\\n",
    "    [int(max(lin_hidden_size, num_classes)) \\\n",
    "          for i in np.arange(1, num_lin_layers, 1)] + [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5886693c-e669-4d8d-b741-06f646008aee",
   "metadata": {},
   "source": [
    "### Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40861ba0-d302-49c3-841f-67c27ecbfa38",
   "metadata": {},
   "source": [
    "#### GCN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36db4e33-ce19-4a37-ad40-f6a3d1fd2315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cell Line E116...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6935580372810364, Valid Loss = 0.6936882734298706\n",
      "Epoch 100: Train Loss = 0.42203575372695923, Valid Loss = 0.435624897480011\n",
      "Epoch 200: Train Loss = 0.37795814871788025, Valid Loss = 0.3977866470813751\n",
      "Epoch 300: Train Loss = 0.36957046389579773, Valid Loss = 0.3947499394416809\n",
      "Epoch 400: Train Loss = 0.362991601228714, Valid Loss = 0.388906866312027\n",
      "Epoch 500: Train Loss = 0.3603886067867279, Valid Loss = 0.39000430703163147\n",
      "Epoch 600: Train Loss = 0.35582607984542847, Valid Loss = 0.385602742433548\n",
      "Epoch 700: Train Loss = 0.35273268818855286, Valid Loss = 0.38617581129074097\n",
      "Epoch 800: Train Loss = 0.3484351634979248, Valid Loss = 0.38903307914733887\n",
      "Epoch 900: Train Loss = 0.3459504246711731, Valid Loss = 0.3883751928806305\n",
      "E116 Test AUROC: 0.9099551151761517, Test Accuracy: 0.844311377245509\n",
      "\n",
      "Training Cell Line E122...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6971882581710815, Valid Loss = 0.6985690593719482\n",
      "Epoch 100: Train Loss = 0.44630101323127747, Valid Loss = 0.4357169568538666\n",
      "Epoch 200: Train Loss = 0.41603001952171326, Valid Loss = 0.3960912525653839\n",
      "Epoch 300: Train Loss = 0.40852200984954834, Valid Loss = 0.38651132583618164\n",
      "Epoch 400: Train Loss = 0.39983564615249634, Valid Loss = 0.3798280656337738\n",
      "Epoch 500: Train Loss = 0.3928184509277344, Valid Loss = 0.38065698742866516\n",
      "Epoch 600: Train Loss = 0.3873274326324463, Valid Loss = 0.3773466944694519\n",
      "Epoch 700: Train Loss = 0.38269346952438354, Valid Loss = 0.3778487741947174\n",
      "Epoch 800: Train Loss = 0.37969309091567993, Valid Loss = 0.37775275111198425\n",
      "Epoch 900: Train Loss = 0.37604886293411255, Valid Loss = 0.37790775299072266\n",
      "E122 Test AUROC: 0.9032637002174007, Test Accuracy: 0.8310027966440272\n",
      "\n",
      "Training Cell Line E123...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6946658492088318, Valid Loss = 0.6945374608039856\n",
      "Epoch 100: Train Loss = 0.4117818772792816, Valid Loss = 0.4098265767097473\n",
      "Epoch 200: Train Loss = 0.35735830664634705, Valid Loss = 0.35761603713035583\n",
      "Epoch 300: Train Loss = 0.3441219627857208, Valid Loss = 0.35291704535484314\n",
      "Epoch 400: Train Loss = 0.3374658524990082, Valid Loss = 0.35109883546829224\n",
      "Epoch 500: Train Loss = 0.33361655473709106, Valid Loss = 0.346917062997818\n",
      "Epoch 600: Train Loss = 0.3284868896007538, Valid Loss = 0.3447571098804474\n",
      "Epoch 700: Train Loss = 0.32277730107307434, Valid Loss = 0.34344378113746643\n",
      "Epoch 800: Train Loss = 0.319350004196167, Valid Loss = 0.34578830003738403\n",
      "Epoch 900: Train Loss = 0.31465038657188416, Valid Loss = 0.3440421223640442\n",
      "E123 Test AUROC: 0.9230188838630902, Test Accuracy: 0.8610223642172524\n"
     ]
    }
   ],
   "source": [
    "gcn_auroc = []\n",
    "gcn_acc = []\n",
    "all_gcn_losses = []\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    print(f'\\nTraining Cell Line {cell_line}...')\n",
    "    \n",
    "    train_idx = torch.load(f'../train-test-split/{cell_line}/train_idx.pt')\n",
    "    valid_idx = torch.load(f'../train-test-split/{cell_line}/valid_idx.pt')\n",
    "    test_idx = torch.load(f'../train-test-split/{cell_line}/test_idx.pt')\n",
    "    \n",
    "    G, targetNode_mask = prepare_data(cell_line=cell_line, regression_flag = regression_flag, base_path = src_dir)\n",
    "    model = GCN_classification(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, graph_lin_hidden_sizes, num_classes)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    \n",
    "    gcn_train_losses, gcn_valid_losses = train_model_classification(model, loss, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "    gcn_out = eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "\n",
    "    all_gcn_losses.append([gcn_train_losses, gcn_valid_losses])\n",
    "    \n",
    "    gcn_test_AUROC = gcn_out[\"test_AUROC\"]\n",
    "    gcn_auroc.append(gcn_test_AUROC)\n",
    "    \n",
    "    gcn_test_acc = gcn_out[\"test_acc\"]\n",
    "    gcn_acc.append(gcn_test_acc)\n",
    "    \n",
    "    print(f\"{cell_line} Test AUROC: {gcn_test_AUROC}, Test Accuracy: {gcn_test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960aa44a-8b9c-4554-8d1c-296dba6f1580",
   "metadata": {},
   "source": [
    "#### MLP Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c410ec-d29c-4fb6-bc9e-72e379fa2bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cell Line E116...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6892363429069519, Valid Loss = 0.6896421313285828\n",
      "Epoch 100: Train Loss = 0.541705310344696, Valid Loss = 0.5454736948013306\n",
      "Epoch 200: Train Loss = 0.4273169934749603, Valid Loss = 0.4391532838344574\n",
      "Epoch 300: Train Loss = 0.40098610520362854, Valid Loss = 0.4161554276943207\n",
      "Epoch 400: Train Loss = 0.3905988037586212, Valid Loss = 0.4068722128868103\n",
      "Epoch 500: Train Loss = 0.3847435712814331, Valid Loss = 0.40175551176071167\n",
      "Epoch 600: Train Loss = 0.38063669204711914, Valid Loss = 0.39862364530563354\n",
      "Epoch 700: Train Loss = 0.3776399791240692, Valid Loss = 0.3967739939689636\n",
      "Epoch 800: Train Loss = 0.3754136860370636, Valid Loss = 0.3956705927848816\n",
      "Epoch 900: Train Loss = 0.3736962676048279, Valid Loss = 0.39498934149742126\n",
      "E116 Test AUROC: 0.9089087008294325, Test Accuracy: 0.8407185628742515\n",
      "\n",
      "Training Cell Line E122...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6940168738365173, Valid Loss = 0.6946899890899658\n",
      "Epoch 100: Train Loss = 0.5908188223838806, Valid Loss = 0.5863165259361267\n",
      "Epoch 200: Train Loss = 0.48145395517349243, Valid Loss = 0.4686304032802582\n",
      "Epoch 300: Train Loss = 0.4446919560432434, Valid Loss = 0.4256761968135834\n",
      "Epoch 400: Train Loss = 0.43203258514404297, Valid Loss = 0.41217339038848877\n",
      "Epoch 500: Train Loss = 0.424876868724823, Valid Loss = 0.4047538638114929\n",
      "Epoch 600: Train Loss = 0.4187880754470825, Valid Loss = 0.39839041233062744\n",
      "Epoch 700: Train Loss = 0.41482439637184143, Valid Loss = 0.39430856704711914\n",
      "Epoch 800: Train Loss = 0.4121668040752411, Valid Loss = 0.3918740749359131\n",
      "Epoch 900: Train Loss = 0.41017287969589233, Valid Loss = 0.3901084363460541\n",
      "E122 Test AUROC: 0.8960957485218539, Test Accuracy: 0.8262085497403117\n",
      "\n",
      "Training Cell Line E123...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.7027177810668945, Valid Loss = 0.7024230360984802\n",
      "Epoch 100: Train Loss = 0.5638828873634338, Valid Loss = 0.5664588212966919\n",
      "Epoch 200: Train Loss = 0.43620896339416504, Valid Loss = 0.4408595561981201\n",
      "Epoch 300: Train Loss = 0.3958422541618347, Valid Loss = 0.4000522792339325\n",
      "Epoch 400: Train Loss = 0.38060304522514343, Valid Loss = 0.3840877115726471\n",
      "Epoch 500: Train Loss = 0.3702321946620941, Valid Loss = 0.37279513478279114\n",
      "Epoch 600: Train Loss = 0.36296945810317993, Valid Loss = 0.36466702818870544\n",
      "Epoch 700: Train Loss = 0.35861170291900635, Valid Loss = 0.35952869057655334\n",
      "Epoch 800: Train Loss = 0.355938196182251, Valid Loss = 0.3559361696243286\n",
      "Epoch 900: Train Loss = 0.35382139682769775, Valid Loss = 0.3531688153743744\n",
      "E123 Test AUROC: 0.9183190366849182, Test Accuracy: 0.8538338658146964\n"
     ]
    }
   ],
   "source": [
    "mlp_auroc = []\n",
    "mlp_acc = []\n",
    "all_mlp_losses = []\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    print(f'\\nTraining Cell Line {cell_line}...')\n",
    "\n",
    "    train_idx = torch.load(f'../train-test-split/{cell_line}/train_idx.pt')\n",
    "    valid_idx = torch.load(f'../train-test-split/{cell_line}/valid_idx.pt')\n",
    "    test_idx = torch.load(f'../train-test-split/{cell_line}/test_idx.pt')\n",
    "    \n",
    "    G, targetNode_mask = prepare_data(cell_line=cell_line, regression_flag = regression_flag, base_path = src_dir)\n",
    "    model = MLP_classification(num_feat, num_lin_layers, lin_hidden_sizes, num_classes)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    \n",
    "    mlp_train_losses, mlp_valid_losses = train_model_classification(model, loss, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "    mlp_out = eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "\n",
    "    all_mlp_losses.append([mlp_train_losses, mlp_valid_losses])\n",
    "\n",
    "    mlp_test_AUROC = mlp_out[\"test_AUROC\"]\n",
    "    mlp_auroc.append(mlp_test_AUROC)\n",
    "\n",
    "    mlp_test_acc = mlp_out[\"test_acc\"]\n",
    "    mlp_acc.append(mlp_test_acc)\n",
    "    \n",
    "    print(f\"{cell_line} Test AUROC: {mlp_test_AUROC}, Test Accuracy: {mlp_test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89610dc-b5ba-4619-8970-f8e43d568dca",
   "metadata": {},
   "source": [
    "#### Weighted Aggregation GCN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59a83ea4-64bb-4944-830f-7b10d955e541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cell Line E116...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6935580372810364, Valid Loss = 0.6936882734298706\n",
      "Epoch 100: Train Loss = 0.42202967405319214, Valid Loss = 0.4356260597705841\n",
      "Epoch 200: Train Loss = 0.37797003984451294, Valid Loss = 0.3978056311607361\n",
      "Epoch 300: Train Loss = 0.369561105966568, Valid Loss = 0.39496418833732605\n",
      "Epoch 400: Train Loss = 0.363079696893692, Valid Loss = 0.38908401131629944\n",
      "Epoch 500: Train Loss = 0.3603517413139343, Valid Loss = 0.39001116156578064\n",
      "Epoch 600: Train Loss = 0.3558855652809143, Valid Loss = 0.3855525851249695\n",
      "Epoch 700: Train Loss = 0.35269609093666077, Valid Loss = 0.38606080412864685\n",
      "Epoch 800: Train Loss = 0.34844595193862915, Valid Loss = 0.389275461435318\n",
      "Epoch 900: Train Loss = 0.34594160318374634, Valid Loss = 0.3892585337162018\n",
      "Epoch 1000: Train Loss = 0.3426258862018585, Valid Loss = 0.38658204674720764\n",
      "Epoch 1100: Train Loss = 0.3379587233066559, Valid Loss = 0.3919593095779419\n",
      "Epoch 1200: Train Loss = 0.33729061484336853, Valid Loss = 0.3946612477302551\n",
      "Epoch 1300: Train Loss = 0.33269038796424866, Valid Loss = 0.3951900005340576\n",
      "Epoch 1400: Train Loss = 0.32682403922080994, Valid Loss = 0.39981284737586975\n",
      "E116 Test AUROC: 0.9022600240206948, Test Accuracy: 0.8419161676646707\n",
      "\n",
      "Training Cell Line E122...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6971882581710815, Valid Loss = 0.6985690593719482\n",
      "Epoch 100: Train Loss = 0.44629988074302673, Valid Loss = 0.4357203245162964\n",
      "Epoch 200: Train Loss = 0.41604840755462646, Valid Loss = 0.3960217833518982\n",
      "Epoch 300: Train Loss = 0.4085531234741211, Valid Loss = 0.3865421712398529\n",
      "Epoch 400: Train Loss = 0.39982444047927856, Valid Loss = 0.3800727128982544\n",
      "Epoch 500: Train Loss = 0.3929706811904907, Valid Loss = 0.38078033924102783\n",
      "Epoch 600: Train Loss = 0.38715115189552307, Valid Loss = 0.37754499912261963\n",
      "Epoch 700: Train Loss = 0.3829272389411926, Valid Loss = 0.3778712749481201\n",
      "Epoch 800: Train Loss = 0.3801252841949463, Valid Loss = 0.37740302085876465\n",
      "Epoch 900: Train Loss = 0.37600353360176086, Valid Loss = 0.37660521268844604\n",
      "Epoch 1000: Train Loss = 0.37413349747657776, Valid Loss = 0.375310480594635\n",
      "Epoch 1100: Train Loss = 0.37267306447029114, Valid Loss = 0.38042762875556946\n",
      "Epoch 1200: Train Loss = 0.3683266043663025, Valid Loss = 0.38314691185951233\n",
      "Epoch 1300: Train Loss = 0.3667415678501129, Valid Loss = 0.3790622651576996\n",
      "Epoch 1400: Train Loss = 0.3608141541481018, Valid Loss = 0.3805921673774719\n",
      "E122 Test AUROC: 0.9018444496226854, Test Accuracy: 0.8361965641230523\n",
      "\n",
      "Training Cell Line E123...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6946658492088318, Valid Loss = 0.694537341594696\n",
      "Epoch 100: Train Loss = 0.4116836190223694, Valid Loss = 0.409686803817749\n",
      "Epoch 200: Train Loss = 0.35728248953819275, Valid Loss = 0.3574773371219635\n",
      "Epoch 300: Train Loss = 0.3442288339138031, Valid Loss = 0.35250741243362427\n",
      "Epoch 400: Train Loss = 0.3375457525253296, Valid Loss = 0.3512684404850006\n",
      "Epoch 500: Train Loss = 0.3335362374782562, Valid Loss = 0.34687045216560364\n",
      "Epoch 600: Train Loss = 0.32808664441108704, Valid Loss = 0.3443550169467926\n",
      "Epoch 700: Train Loss = 0.3236778974533081, Valid Loss = 0.343456506729126\n",
      "Epoch 800: Train Loss = 0.31958290934562683, Valid Loss = 0.3451097309589386\n",
      "Epoch 900: Train Loss = 0.315200537443161, Valid Loss = 0.3429926335811615\n",
      "Epoch 1000: Train Loss = 0.3105829954147339, Valid Loss = 0.3465275168418884\n",
      "Epoch 1100: Train Loss = 0.307710736989975, Valid Loss = 0.3490382730960846\n",
      "Epoch 1200: Train Loss = 0.30284860730171204, Valid Loss = 0.34740009903907776\n",
      "Epoch 1300: Train Loss = 0.3005061745643616, Valid Loss = 0.35943472385406494\n",
      "Epoch 1400: Train Loss = 0.2967718839645386, Valid Loss = 0.35609182715415955\n",
      "E123 Test AUROC: 0.9196571876175923, Test Accuracy: 0.8570287539936102\n"
     ]
    }
   ],
   "source": [
    "w_gcn_auroc = []\n",
    "w_gcn_acc = []\n",
    "all_w_gcn_losses = []\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    print(f'\\nTraining Cell Line {cell_line}...')\n",
    "\n",
    "    train_idx = torch.load(f'../train-test-split/{cell_line}/train_idx.pt')\n",
    "    valid_idx = torch.load(f'../train-test-split/{cell_line}/valid_idx.pt')\n",
    "    test_idx = torch.load(f'../train-test-split/{cell_line}/test_idx.pt')\n",
    "    \n",
    "    G, targetNode_mask = prepare_data(cell_line = cell_line, regression_flag = regression_flag, base_path = src_dir)\n",
    "    model = GCN_classification_weighted(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, graph_lin_hidden_sizes, num_classes, num_nodes=G.x.shape[0], edge_attr=G.edge_attr)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    \n",
    "    w_gcn_train_losses, w_gcn_valid_losses = train_model_classification(model, loss, G, max_epoch_weighted_agg, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "    w_gcn_out = eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "\n",
    "    all_w_gcn_losses.append([w_gcn_train_losses, w_gcn_valid_losses])\n",
    "\n",
    "    w_gcn_test_AUROC = w_gcn_out[\"test_AUROC\"]\n",
    "    w_gcn_auroc.append(w_gcn_test_AUROC)\n",
    "\n",
    "    w_gcn_test_acc = w_gcn_out[\"test_acc\"]\n",
    "    w_gcn_acc.append(w_gcn_test_acc)\n",
    "    \n",
    "    print(f\"{cell_line} Test AUROC: {w_gcn_test_AUROC}, Test Accuracy: {w_gcn_test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d56391-f606-4463-8766-7861607ecd6a",
   "metadata": {},
   "source": [
    "#### GAT Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6840953-c4e1-461d-832d-5320d3f18375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cell Line E116...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.7010973691940308, Valid Loss = 0.6971675157546997\n",
      "Epoch 100: Train Loss = 0.5876685976982117, Valid Loss = 0.5974135398864746\n",
      "Epoch 200: Train Loss = 0.5228026509284973, Valid Loss = 0.5355121493339539\n",
      "Epoch 300: Train Loss = 0.49715372920036316, Valid Loss = 0.5143245458602905\n",
      "Epoch 400: Train Loss = 0.45887693762779236, Valid Loss = 0.48942384123802185\n",
      "Epoch 500: Train Loss = 0.4416870176792145, Valid Loss = 0.4674643874168396\n",
      "Epoch 600: Train Loss = 0.42829152941703796, Valid Loss = 0.46398159861564636\n",
      "Epoch 700: Train Loss = 0.42272740602493286, Valid Loss = 0.45701536536216736\n",
      "Epoch 800: Train Loss = 0.4185510277748108, Valid Loss = 0.45829907059669495\n",
      "Epoch 900: Train Loss = 0.4136381447315216, Valid Loss = 0.4563336670398712\n",
      "E116 Test AUROC: 0.8798400673400675, Test Accuracy: 0.8135728542914171\n",
      "\n",
      "Training Cell Line E122...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6988705396652222, Valid Loss = 0.7006978988647461\n",
      "Epoch 100: Train Loss = 0.5306304693222046, Valid Loss = 0.5302071571350098\n",
      "Epoch 200: Train Loss = 0.4957829415798187, Valid Loss = 0.49399426579475403\n",
      "Epoch 300: Train Loss = 0.4651743173599243, Valid Loss = 0.4663389325141907\n",
      "Epoch 400: Train Loss = 0.453022301197052, Valid Loss = 0.4551317095756531\n",
      "Epoch 500: Train Loss = 0.4469034671783447, Valid Loss = 0.44563305377960205\n",
      "Epoch 600: Train Loss = 0.4423435926437378, Valid Loss = 0.4428332448005676\n",
      "Epoch 700: Train Loss = 0.43972307443618774, Valid Loss = 0.4411596357822418\n",
      "Epoch 800: Train Loss = 0.43677952885627747, Valid Loss = 0.44063621759414673\n",
      "Epoch 900: Train Loss = 0.43289998173713684, Valid Loss = 0.4348675310611725\n",
      "E122 Test AUROC: 0.8789757581499682, Test Accuracy: 0.8110267678785458\n",
      "\n",
      "Training Cell Line E123...\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.696287214756012, Valid Loss = 0.6968921422958374\n",
      "Epoch 100: Train Loss = 0.546142578125, Valid Loss = 0.5458626747131348\n",
      "Epoch 200: Train Loss = 0.4940817654132843, Valid Loss = 0.49543097615242004\n",
      "Epoch 300: Train Loss = 0.4545300304889679, Valid Loss = 0.45535391569137573\n",
      "Epoch 400: Train Loss = 0.43450039625167847, Valid Loss = 0.44470155239105225\n",
      "Epoch 500: Train Loss = 0.4251561760902405, Valid Loss = 0.4326210021972656\n",
      "Epoch 600: Train Loss = 0.418352335691452, Valid Loss = 0.4318446218967438\n",
      "Epoch 700: Train Loss = 0.40967220067977905, Valid Loss = 0.42300212383270264\n",
      "Epoch 800: Train Loss = 0.4060288369655609, Valid Loss = 0.4260213375091553\n",
      "Epoch 900: Train Loss = 0.4024132192134857, Valid Loss = 0.42499664425849915\n",
      "E123 Test AUROC: 0.8943999887367495, Test Accuracy: 0.8190894568690096\n"
     ]
    }
   ],
   "source": [
    "gat_auroc = []\n",
    "gat_acc = []\n",
    "all_gat_losses = []\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    print(f'\\nTraining Cell Line {cell_line}...')\n",
    "\n",
    "    train_idx = torch.load(f'../train-test-split/{cell_line}/train_idx.pt')\n",
    "    valid_idx = torch.load(f'../train-test-split/{cell_line}/valid_idx.pt')\n",
    "    test_idx = torch.load(f'../train-test-split/{cell_line}/test_idx.pt')\n",
    "\n",
    "    G, targetNode_mask = prepare_data(cell_line = cell_line, regression_flag = regression_flag, base_path = src_dir)\n",
    "    gat = GAT(in_channels = 6, hidden_channels = GAT_hidden_channels, num_heads = GAT_num_heads, dropout = GAT_dropout)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, gat.parameters()), lr = GAT_lr, weight_decay = GAT_wd)\n",
    "    \n",
    "    gat_train_losses, gat_valid_losses = train_model_classification(gat, loss, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "    gat_out = eval_model_classification(gat, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "\n",
    "    all_gat_losses.append([gat_train_losses, gat_valid_losses])\n",
    "    \n",
    "    gat_test_AUROC = gat_out[\"test_AUROC\"]\n",
    "    gat_auroc.append(gat_test_AUROC)\n",
    "\n",
    "    gat_test_acc = gat_out[\"test_acc\"]\n",
    "    gat_acc.append(gat_test_acc)\n",
    "    print(f\"{cell_line} Test AUROC: {gat_test_AUROC}, Test Accuracy: {gat_test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47d932-b936-46c4-8ae8-19680422bbca",
   "metadata": {},
   "source": [
    "#### Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3df0ee1-4fe5-4527-a305-750c6ed0c8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E116</th>\n",
       "      <th>E122</th>\n",
       "      <th>E123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.909955</td>\n",
       "      <td>0.903264</td>\n",
       "      <td>0.923019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.908909</td>\n",
       "      <td>0.896096</td>\n",
       "      <td>0.918319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted_Agg_GCN</th>\n",
       "      <td>0.902260</td>\n",
       "      <td>0.901844</td>\n",
       "      <td>0.919657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAT</th>\n",
       "      <td>0.879840</td>\n",
       "      <td>0.878976</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      E116      E122      E123\n",
       "GCN               0.909955  0.903264  0.923019\n",
       "MLP               0.908909  0.896096  0.918319\n",
       "Weighted_Agg_GCN  0.902260  0.901844  0.919657\n",
       "GAT               0.879840  0.878976  0.894400"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_auroc_res = pd.DataFrame(columns = cell_lines)\n",
    "classification_auroc_res.loc['GCN'] = gcn_auroc\n",
    "classification_auroc_res.loc['MLP'] = mlp_auroc\n",
    "classification_auroc_res.loc['Weighted_Agg_GCN'] = w_gcn_auroc\n",
    "classification_auroc_res.loc['GAT'] = gat_auroc\n",
    "classification_auroc_res.to_csv('classification_AUROC_res.csv')\n",
    "classification_auroc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "972d1a44-36ca-40bb-bebf-4b1bdd9b8628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E116</th>\n",
       "      <th>E122</th>\n",
       "      <th>E123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.844311</td>\n",
       "      <td>0.831003</td>\n",
       "      <td>0.861022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.840719</td>\n",
       "      <td>0.826209</td>\n",
       "      <td>0.853834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted_Agg_GCN</th>\n",
       "      <td>0.841916</td>\n",
       "      <td>0.836197</td>\n",
       "      <td>0.857029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAT</th>\n",
       "      <td>0.813573</td>\n",
       "      <td>0.811027</td>\n",
       "      <td>0.819089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      E116      E122      E123\n",
       "GCN               0.844311  0.831003  0.861022\n",
       "MLP               0.840719  0.826209  0.853834\n",
       "Weighted_Agg_GCN  0.841916  0.836197  0.857029\n",
       "GAT               0.813573  0.811027  0.819089"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_acc_res = pd.DataFrame(columns = cell_lines)\n",
    "classification_acc_res.loc['GCN'] = gcn_acc\n",
    "classification_acc_res.loc['MLP'] = mlp_acc\n",
    "classification_acc_res.loc['Weighted_Agg_GCN'] = w_gcn_acc\n",
    "classification_acc_res.loc['GAT'] = gat_acc\n",
    "classification_acc_res.to_csv('classification_accuracy_res.csv')\n",
    "classification_acc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "596d1971-3df1-499a-aca5-8c365219be80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E116</th>\n",
       "      <th>E122</th>\n",
       "      <th>E123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>[[0.6935580372810364, 0.6931409239768982, 0.69...</td>\n",
       "      <td>[[0.6971882581710815, 0.6967305541038513, 0.69...</td>\n",
       "      <td>[[0.6946658492088318, 0.6942091584205627, 0.69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>[[0.6892363429069519, 0.6878113150596619, 0.68...</td>\n",
       "      <td>[[0.6940168738365173, 0.692836344242096, 0.691...</td>\n",
       "      <td>[[0.7027177810668945, 0.7012646794319153, 0.69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted_Agg_GCN</th>\n",
       "      <td>[[0.6935580372810364, 0.6931409239768982, 0.69...</td>\n",
       "      <td>[[0.6971882581710815, 0.6967305541038513, 0.69...</td>\n",
       "      <td>[[0.6946658492088318, 0.6942091584205627, 0.69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAT</th>\n",
       "      <td>[[0.7010973691940308, 0.7005693316459656, 0.70...</td>\n",
       "      <td>[[0.6988705396652222, 0.6982897520065308, 0.69...</td>\n",
       "      <td>[[0.696287214756012, 0.6958156228065491, 0.695...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               E116  \\\n",
       "GCN               [[0.6935580372810364, 0.6931409239768982, 0.69...   \n",
       "MLP               [[0.6892363429069519, 0.6878113150596619, 0.68...   \n",
       "Weighted_Agg_GCN  [[0.6935580372810364, 0.6931409239768982, 0.69...   \n",
       "GAT               [[0.7010973691940308, 0.7005693316459656, 0.70...   \n",
       "\n",
       "                                                               E122  \\\n",
       "GCN               [[0.6971882581710815, 0.6967305541038513, 0.69...   \n",
       "MLP               [[0.6940168738365173, 0.692836344242096, 0.691...   \n",
       "Weighted_Agg_GCN  [[0.6971882581710815, 0.6967305541038513, 0.69...   \n",
       "GAT               [[0.6988705396652222, 0.6982897520065308, 0.69...   \n",
       "\n",
       "                                                               E123  \n",
       "GCN               [[0.6946658492088318, 0.6942091584205627, 0.69...  \n",
       "MLP               [[0.7027177810668945, 0.7012646794319153, 0.69...  \n",
       "Weighted_Agg_GCN  [[0.6946658492088318, 0.6942091584205627, 0.69...  \n",
       "GAT               [[0.696287214756012, 0.6958156228065491, 0.695...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses = pd.DataFrame(columns = cell_lines)\n",
    "all_losses.loc['GCN'] = all_gcn_losses\n",
    "all_losses.loc['MLP'] = all_mlp_losses\n",
    "all_losses.loc['Weighted_Agg_GCN'] = all_w_gcn_losses\n",
    "all_losses.loc['GAT'] = all_gat_losses\n",
    "all_losses.to_csv('all_losses.csv')\n",
    "all_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e761a-e0e5-41b7-96f5-28a9ff9a3125",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee7428-721c-4bb8-b31c-9fe72a4c3987",
   "metadata": {},
   "source": [
    "#### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "484ec6bc-057d-4865-88ed-6709072befd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cell Line E116...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "Pearson: 0.7661645753475331\n",
      "\n",
      "Training Cell Line E122...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "Pearson: 0.7691094216951544\n",
      "\n",
      "Training Cell Line E123...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "Pearson: 0.7943608624082945\n"
     ]
    }
   ],
   "source": [
    "gcn_pearson = {}\n",
    "gcn_preds_reg_E116, gcn_preds_lab_E116 = [], []\n",
    "gcn_preds_reg_E122, gcn_preds_lab_E122 = [], []\n",
    "gcn_preds_reg_E123, gcn_preds_lab_E123 = [], []\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    \n",
    "    train_idx = torch.load(f'../train-test-split/{cell_line}/train_idx.pt')\n",
    "    valid_idx = torch.load(f'../train-test-split/{cell_line}/valid_idx.pt')\n",
    "    test_idx = torch.load(f'../train-test-split/{cell_line}/test_idx.pt')\n",
    "    \n",
    "    print(f'\\nTraining Cell Line {cell_line}...')\n",
    "    G, targetNode_mask = prepare_data(cell_line=cell_line, regression_flag = 1, base_path = src_dir)\n",
    "    \n",
    "    model = GCN_regression(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, graph_lin_hidden_sizes_reg, num_classes_reg)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    \n",
    "    train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec = \\\n",
    "        train_model_regression(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "    \n",
    "    test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "        valid_pearson, valid_pred, valid_labels = \\\n",
    "            eval_model_regression(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "    \n",
    "    if cell_line == 'E116':\n",
    "        gcn_preds_reg_E116.append(test_pred)\n",
    "        gcn_preds_lab_E116.append(test_labels)\n",
    "    elif cell_line == 'E122':\n",
    "        gcn_preds_reg_E122.append(test_pred)\n",
    "        gcn_preds_lab_E122.append(test_labels)\n",
    "    elif cell_line == 'E123':\n",
    "        gcn_preds_reg_E123.append(test_pred)\n",
    "        gcn_preds_lab_E123.append(test_labels)\n",
    "    \n",
    "    gcn_pearson[cell_line] = test_pearson\n",
    "    print(f\"Pearson: {test_pearson}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baefa8e-7cb7-4aac-af20-3362df54fe0a",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a97a8af-9fad-4ce2-b19d-ca59d4e5368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cell Line E116...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "Pearson: 0.7244821373288937\n",
      "\n",
      "Training Cell Line E122...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "Pearson: 0.6731905849926105\n",
      "\n",
      "Training Cell Line E123...\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "Pearson: 0.7235219911781169\n"
     ]
    }
   ],
   "source": [
    "mlp_pearson = {}\n",
    "mlp_preds_reg_E116, mlp_preds_lab_E116 = [], []\n",
    "mlp_preds_reg_E122, mlp_preds_lab_E122 = [], []\n",
    "mlp_preds_reg_E123, mlp_preds_lab_E123 = [], []\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    \n",
    "    train_idx = torch.load(f'../train-test-split/{cell_line}/train_idx.pt')\n",
    "    valid_idx = torch.load(f'../train-test-split/{cell_line}/valid_idx.pt')\n",
    "    test_idx = torch.load(f'../train-test-split/{cell_line}/test_idx.pt')\n",
    "    \n",
    "    print(f'\\nTraining Cell Line {cell_line}...')\n",
    "    G, targetNode_mask = prepare_data(cell_line=cell_line, regression_flag=1, base_path=src_dir)\n",
    "    \n",
    "    # Initialize MLP regression model\n",
    "    model = MLP_regression(\n",
    "    num_feat=6, \n",
    "    num_lin_layers=2,\n",
    "    lin_hidden_sizes=[256, 128],  # Ensure this is a list with at least three values\n",
    "    num_classes=1)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "    \n",
    "    train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec = \\\n",
    "        train_model_regression(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "    \n",
    "    test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "        valid_pearson, valid_pred, valid_labels = \\\n",
    "            eval_model_regression(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "    \n",
    "    # Store predictions and labels for the corresponding cell line\n",
    "    if cell_line == 'E116':\n",
    "        mlp_preds_reg_E116.append(test_pred)\n",
    "        mlp_preds_lab_E116.append(test_labels)\n",
    "    elif cell_line == 'E122':\n",
    "        mlp_preds_reg_E122.append(test_pred)\n",
    "        mlp_preds_lab_E122.append(test_labels)\n",
    "    elif cell_line == 'E123':\n",
    "        mlp_preds_reg_E123.append(test_pred)\n",
    "        mlp_preds_lab_E123.append(test_labels)\n",
    "    \n",
    "    # Update Pearson dictionary for MLP\n",
    "    mlp_pearson[cell_line] = test_pearson\n",
    "    print(f\"Pearson: {test_pearson}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0697f195-de12-40e4-89e1-9607a250f20e",
   "metadata": {},
   "source": [
    "#### Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b36a117-d590-4f6e-8be1-b33b9e4e61c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E116</th>\n",
       "      <th>E122</th>\n",
       "      <th>E123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.766165</td>\n",
       "      <td>0.769109</td>\n",
       "      <td>0.794361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.724482</td>\n",
       "      <td>0.673191</td>\n",
       "      <td>0.723522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         E116      E122      E123\n",
       "GCN  0.766165  0.769109  0.794361\n",
       "MLP  0.724482  0.673191  0.723522"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_res = pd.DataFrame(columns = cell_lines)\n",
    "regression_res.loc['GCN'] = gcn_pearson\n",
    "regression_res.loc['MLP'] = mlp_pearson\n",
    "regression_res.to_csv('regression_res.csv')\n",
    "regression_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95703733-d5b4-4a5c-a979-1acdacb73856",
   "metadata": {},
   "source": [
    "#### Saving files for visualizations in figures.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c79d0e1-cc9a-4ebf-b2e6-a66f74e58c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save all npy arrays in one place\n",
    "directory = 'scatter_data_regression'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save the files in the created directory\n",
    "np.save(os.path.join(directory, 'gcn_preds_reg_E116.npy'), gcn_preds_reg_E116[0])\n",
    "np.save(os.path.join(directory, 'gcn_preds_lab_E116.npy'), gcn_preds_lab_E116[0])\n",
    "\n",
    "np.save(os.path.join(directory, 'gcn_preds_reg_E123.npy'), gcn_preds_reg_E123[0])\n",
    "np.save(os.path.join(directory, 'gcn_preds_lab_E123.npy'), gcn_preds_lab_E123[0])\n",
    "\n",
    "np.save(os.path.join(directory, 'gcn_preds_reg_E122.npy'), gcn_preds_reg_E122[0])\n",
    "np.save(os.path.join(directory, 'gcn_preds_lab_E122.npy'), gcn_preds_lab_E122[0])\n",
    "\n",
    "np.save(os.path.join(directory, 'mlp_preds_reg_E116.npy'), mlp_preds_reg_E116[0])\n",
    "np.save(os.path.join(directory, 'mlp_preds_lab_E116.npy'), mlp_preds_lab_E116[0])\n",
    "\n",
    "np.save(os.path.join(directory, 'mlp_preds_reg_E123.npy'), mlp_preds_reg_E123[0])\n",
    "np.save(os.path.join(directory, 'mlp_preds_lab_E123.npy'), mlp_preds_lab_E123[0])\n",
    "\n",
    "np.save(os.path.join(directory, 'mlp_preds_reg_E122.npy'), mlp_preds_reg_E122[0])\n",
    "np.save(os.path.join(directory, 'mlp_preds_lab_E122.npy'), mlp_preds_lab_E122[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06015a-2dd7-45c2-8a70-ba540bfd9783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
