{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8d3722-c832-4427-a22f-3c5dc1465efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.conv import GATConv\n",
    "from model_classes_ import GCN_classification, GCN_regression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9397669-9b16-4592-8024-ffc2ffc54d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4591c0-cd43-4709-a908-dcce5f74c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_flag = 0\n",
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)\n",
    "num_classes = 2 if regression_flag == 0 else 1\n",
    "src_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e1c1b08-e449-4a38-8387-db4d1c6f2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(cell_line, regression_flag, base_path):\n",
    "    save_dir = os.path.join(base_path, 'data', cell_line, 'saved_runs')\n",
    "    hic_sparse_mat_file = os.path.join(base_path, 'data', cell_line, 'hic_sparse.npz')\n",
    "    np_nodes_lab_genes_file = os.path.join(base_path, 'data',  cell_line, \\\n",
    "        'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')\n",
    "    np_hmods_norm_all_file = os.path.join(base_path, 'data', cell_line, \\\n",
    "        'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "    df_genes_file = os.path.join(base_path, 'data', cell_line, 'df_genes_reg' + str(regression_flag) + '.pkl')\n",
    "    df_genes = pd.read_pickle(df_genes_file)\n",
    "    \n",
    "    mat = load_npz(hic_sparse_mat_file)\n",
    "    allNodes_hms = np.load(np_hmods_norm_all_file)\n",
    "    hms = allNodes_hms[:, 1:] #only includes features, not node ids\n",
    "    X = torch.tensor(hms).float().reshape(-1, num_feat) \n",
    "    allNodes = allNodes_hms[:, 0].astype(int)\n",
    "    geneNodes_labs = np.load(np_nodes_lab_genes_file)\n",
    "\n",
    "    geneNodes = geneNodes_labs[:, -2].astype(int)\n",
    "    allLabs = -1*np.ones(np.shape(allNodes))\n",
    "\n",
    "    targetNode_mask = torch.tensor(geneNodes).long()\n",
    "\n",
    "    if regression_flag == 0:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "        allLabs[geneNodes] = geneLabs\n",
    "        Y = torch.tensor(allLabs).long()\n",
    "    else:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(float)\n",
    "        allLabs[geneNodes] = geneLabs\n",
    "        Y = torch.tensor(allLabs).float()\n",
    "\n",
    "    extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "    data = torch_geometric.data.Data(edge_index = extract[0], edge_attr = extract[1], x = X, y = Y)\n",
    "    G = data\n",
    "    \n",
    "    return G, targetNode_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a85ece3-fc77-4232-82c0-14ddcc53c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cpu_npy(x):\n",
    "    return x.cpu().detach().numpy()\n",
    "    \n",
    "def train_model_classification(model, loss, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer):\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        all_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "        train_scores = all_scores[train_idx]\n",
    "        \n",
    "        train_loss = loss(train_scores, torch.LongTensor(train_labels).to(device))\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        valid_scores = all_scores[valid_idx]\n",
    "        valid_loss = loss(valid_scores, torch.LongTensor(valid_labels).to(device))\n",
    "        valid_losses.append(valid_loss.item())\n",
    "\n",
    "        if e%100 == 0:\n",
    "            print(f'Epoch {e}: Train Loss = {train_loss}, Valid Loss = {valid_loss}')\n",
    "\n",
    "    return train_losses, valid_losses\n",
    "\n",
    "def eval_model_classification(model, graph, targetNode_mask, train_idx, valid_idx, test_idx):\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "    test_labels = to_cpu_npy(graph.y[targetNode_mask[test_idx]])\n",
    "    \n",
    "    model.eval()\n",
    "    train_status=False\n",
    "\n",
    "    forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "\n",
    "    test_scores = forward_scores[test_idx]\n",
    "    test_softmax = F.softmax(test_scores, dim=1)\n",
    "    test_preds = torch.argmax(test_softmax, dim=1)\n",
    "    \n",
    "    test_softmax = to_cpu_npy(test_softmax)\n",
    "    test_preds = to_cpu_npy(test_preds)\n",
    "    test_AUROC = roc_auc_score(test_labels, test_softmax[:,1], average=\"micro\")\n",
    "    test_acc = np.mean(test_preds == test_labels)\n",
    "\n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    train_scores = forward_scores[train_idx]\n",
    "    train_softmax = F.softmax(train_scores, dim=1)\n",
    "    train_preds = torch.argmax(train_softmax, dim=1)\n",
    "    \n",
    "    train_softmax = to_cpu_npy(train_softmax)\n",
    "    train_preds = to_cpu_npy(train_preds)\n",
    "    train_AUROC = roc_auc_score(train_labels, train_softmax[:,1], average=\"micro\")\n",
    "    train_acc = np.mean(train_preds == train_labels)\n",
    "\n",
    "\n",
    "    return {'train_AUROC': train_AUROC, 'train_acc': train_acc, 'test_AUROC': test_AUROC, 'test_acc': test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ce208c-0f62-4cf3-86e9-a8f835dcbf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_conv_embed_size = 256\n",
    "num_lin_layers = 2\n",
    "lin_hidden_size = 256\n",
    "num_graph_conv_layers = 2\n",
    "learning_rate = 1e-4\n",
    "max_epoch = 1000\n",
    "\n",
    "graph_conv_layer_sizes = [num_feat] + \\\n",
    "    [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "          for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "\n",
    "graph_lin_hidden_sizes = [graph_conv_layer_sizes[-1]] + \\\n",
    "    [int(max(lin_hidden_size, num_classes)) \\\n",
    "          for i in np.arange(1, num_lin_layers, 1)] + [num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bf0cc77-4c5b-41df-8ea8-8311a4286473",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_lines = ['E116', 'E122', 'E123']\n",
    "classification_res = pd.DataFrame(columns=cell_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc423559-6e6c-4e3f-9cbc-91627e0b2bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Cell Line E116...\n",
      "Number of Parameters: 8014790\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6933467984199524, Valid Loss = 0.6932734847068787\n",
      "Epoch 100: Train Loss = 0.4409469962120056, Valid Loss = 0.4537431597709656\n",
      "Epoch 200: Train Loss = 0.3879590332508087, Valid Loss = 0.404672771692276\n",
      "Epoch 300: Train Loss = 0.3765997588634491, Valid Loss = 0.39762553572654724\n",
      "Epoch 400: Train Loss = 0.3687504231929779, Valid Loss = 0.39666035771369934\n",
      "Epoch 500: Train Loss = 0.3661017119884491, Valid Loss = 0.39130309224128723\n",
      "Epoch 600: Train Loss = 0.36265358328819275, Valid Loss = 0.3925759494304657\n",
      "Epoch 700: Train Loss = 0.3627714514732361, Valid Loss = 0.39330190420150757\n",
      "Epoch 800: Train Loss = 0.35871806740760803, Valid Loss = 0.3906503915786743\n",
      "Epoch 900: Train Loss = 0.3562179505825043, Valid Loss = 0.3895350396633148\n",
      "\n",
      "Training Cell Line E122...\n",
      "Number of Parameters: 7025674\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6909933090209961, Valid Loss = 0.6895294785499573\n",
      "Epoch 100: Train Loss = 0.4629949927330017, Valid Loss = 0.4569920301437378\n",
      "Epoch 200: Train Loss = 0.42041701078414917, Valid Loss = 0.40191850066185\n",
      "Epoch 300: Train Loss = 0.4103866219520569, Valid Loss = 0.39136385917663574\n",
      "Epoch 400: Train Loss = 0.4049140512943268, Valid Loss = 0.38697654008865356\n",
      "Epoch 500: Train Loss = 0.39921316504478455, Valid Loss = 0.38150039315223694\n",
      "Epoch 600: Train Loss = 0.39436668157577515, Valid Loss = 0.3742154836654663\n",
      "Epoch 700: Train Loss = 0.39060333371162415, Valid Loss = 0.3775615990161896\n",
      "Epoch 800: Train Loss = 0.388700008392334, Valid Loss = 0.38021090626716614\n",
      "Epoch 900: Train Loss = 0.38378700613975525, Valid Loss = 0.37716415524482727\n",
      "\n",
      "Training Cell Line E123...\n",
      "Number of Parameters: 7219090\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0: Train Loss = 0.6910997033119202, Valid Loss = 0.6911728382110596\n",
      "Epoch 100: Train Loss = 0.42931511998176575, Valid Loss = 0.432420015335083\n",
      "Epoch 200: Train Loss = 0.3691067397594452, Valid Loss = 0.37174054980278015\n",
      "Epoch 300: Train Loss = 0.35282525420188904, Valid Loss = 0.3563859760761261\n",
      "Epoch 400: Train Loss = 0.34729230403900146, Valid Loss = 0.3553068935871124\n",
      "Epoch 500: Train Loss = 0.3426801562309265, Valid Loss = 0.3489539921283722\n",
      "Epoch 600: Train Loss = 0.3386721909046173, Valid Loss = 0.3484988212585449\n",
      "Epoch 700: Train Loss = 0.33439338207244873, Valid Loss = 0.3457070589065552\n",
      "Epoch 800: Train Loss = 0.3318518102169037, Valid Loss = 0.3420201539993286\n",
      "Epoch 900: Train Loss = 0.32922643423080444, Valid Loss = 0.34503665566444397\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E116</th>\n",
       "      <th>E122</th>\n",
       "      <th>E123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weighted_GCN</th>\n",
       "      <td>0.914564</td>\n",
       "      <td>0.906671</td>\n",
       "      <td>0.925247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  E116      E122      E123\n",
       "weighted_GCN  0.914564  0.906671  0.925247"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_auroc = []\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    print(f'\\nTraining Cell Line {cell_line}...')\n",
    "\n",
    "    train_idx = torch.load(f'train-test-split/{cell_line}/train_idx.pt')\n",
    "    valid_idx = torch.load(f'train-test-split/{cell_line}/valid_idx.pt')\n",
    "    test_idx = torch.load(f'train-test-split/{cell_line}/test_idx.pt')\n",
    "    \n",
    "    G, targetNode_mask = prepare_data(cell_line = cell_line, regression_flag = regression_flag, base_path = src_dir)\n",
    "    \n",
    "    model = GCN_classification(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, graph_lin_hidden_sizes, num_classes, num_nodes=G.x.shape[0], num_edges=G.edge_index.shape[1])\n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    print(f'Number of Parameters: {sum([np.prod(p.size()) for p in model_parameters])}')\n",
    "\n",
    "    train_out = train_model_classification(model, loss, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "    test_out = eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "\n",
    "    gcn_auroc.append(test_out['test_AUROC'])\n",
    "\n",
    "classification_res.loc['weighted_GCN'] = gcn_auroc\n",
    "classification_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c64741-7995-4664-8f20-7f9da0b8eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_gcn_res = pd.read_csv('results.csv', index_col=0)\n",
    "res = pd.concat([classification_res, vanilla_gcn_res])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bcb5668-fa5e-4b2e-8eff-c4e60e60851d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E116</th>\n",
       "      <th>E122</th>\n",
       "      <th>E123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weighted_GCN</th>\n",
       "      <td>0.914564</td>\n",
       "      <td>0.906671</td>\n",
       "      <td>0.925247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.911963</td>\n",
       "      <td>0.907248</td>\n",
       "      <td>0.926022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  E116      E122      E123\n",
       "weighted_GCN  0.914564  0.906671  0.925247\n",
       "GCN           0.911963  0.907248  0.926022"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bab180e-2a60-4ced-bfdf-8b2e1a9442b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7219090"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ff087-399b-4c42-abf9-4520cdd03df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
