{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84cf2b34-2bde-4873-84a5-f023bf204db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn.conv import GATConv\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5bf469-4fea-46e0-aeb3-240137d4236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA RTX A5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vvenkatesh/.local/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    for i in range(gpu_count):\n",
    "        device_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {device_name}\")\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "\n",
    "cell_line = 'E116'\n",
    "regression_flag = 0\n",
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)\n",
    "num_classes = 2 if regression_flag == 0 else 1\n",
    "\n",
    "#define data paths\n",
    "src_dir = os.getcwd()\n",
    "#src_dir = os.path.dirname(base_path)\n",
    "save_dir = os.path.join(src_dir, 'data', cell_line, 'saved_runs')\n",
    "hic_sparse_mat_file = os.path.join(src_dir, 'data', cell_line, 'hic_sparse.npz')\n",
    "np_nodes_lab_genes_file = os.path.join(src_dir, 'data',  cell_line, \\\n",
    "    'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')\n",
    "np_hmods_norm_all_file = os.path.join(src_dir, 'data', cell_line, \\\n",
    "    'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "\n",
    "mat = load_npz(hic_sparse_mat_file)\n",
    "allNodes_hms = np.load(np_hmods_norm_all_file) #contains 6 histone marks for all 279606 regions + id (Shape = [279606, 7])\n",
    "hms = allNodes_hms[:, 1:] #only includes features, not node ids (Shape = [279606, 6])\n",
    "X = torch.tensor(hms).float().reshape(-1, num_feat) #convert hms to tensor (Shape = [279606, 6])\n",
    "allNodes = allNodes_hms[:, 0].astype(int) #contains ids of all regions (Shape = [279606, 1])\n",
    "\n",
    "geneNodes_labs = np.load(np_nodes_lab_genes_file) #contains the expression level of each gene (Shape = [16699, 2])\n",
    "geneNodes = geneNodes_labs[:, -2].astype(int) #contains ids of regions that encode a gene (Shape = [16699, 1])\n",
    "\n",
    "allLabs = -1*np.ones(np.shape(allNodes))\n",
    "targetNode_mask = torch.tensor(geneNodes).long()\n",
    "geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "allLabs[geneNodes] = geneLabs #contains expression level for each region (-1 if region doesn't encode gene, 1 if gene is expressed, 0 if not)\n",
    "Y = torch.tensor(allLabs).long()\n",
    "\n",
    "extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "\n",
    "data = torch_geometric.data.Data(edge_index = extract[0], edge_attr = extract[1], x = X, y = Y)\n",
    "G = data\n",
    "\n",
    "pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "train_idx = pred_idx_shuff[:fin_train]\n",
    "valid_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "test_idx = pred_idx_shuff[fin_valid:]\n",
    "\n",
    "train_n_loader = NeighborLoader(G, num_neighbors = [10, 10], batch_size = 64, input_nodes = targetNode_mask[train_idx], shuffle = True)\n",
    "valid_n_loader = NeighborLoader(G, num_neighbors = [10, 10], batch_size = 64, input_nodes = targetNode_mask[valid_idx], shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95833b8-8a57-4380-a979-c6691e4e8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cpu_npy(x):\n",
    "    return x.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b225db5a-715d-4e13-81b7-32360f5c8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_classification(model, loss, train_loader, valid_loader, max_epoch, optimizer, train_idx = train_idx, valid_idx = valid_idx):\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(max_epoch):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            train_batch_mask = torch.isin(batch.n_id.to(device), targetNode_mask.to(device))\n",
    "            train_batch_scores = model(batch)[train_batch_mask]\n",
    "            train_batch_labels = to_cpu_npy(batch.y[train_batch_mask])\n",
    "            train_batch_loss = loss(train_batch_scores, torch.LongTensor(train_batch_labels).to(device))\n",
    "            train_losses.append(train_batch_loss.item())\n",
    "            train_batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                batch = batch.to(device)\n",
    "                valid_batch_mask = torch.isin(batch.n_id.to(device), targetNode_mask.to(device))\n",
    "                valid_batch_scores = model(batch)[valid_batch_mask]\n",
    "                valid_batch_labels = to_cpu_npy(batch.y[valid_batch_mask])\n",
    "                valid_batch_loss = loss(valid_batch_scores, torch.LongTensor(valid_batch_labels).to(device))\n",
    "                valid_losses.append(valid_batch_loss.item())\n",
    "                \n",
    "        print(f'Epoch {epoch}: Train Loss = {train_batch_loss}, Valid Loss = {valid_batch_loss}')\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4634dd-0db2-489c-97aa-24a00d04e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_classification(model, graph, targetNode_mask, train_idx, valid_idx, test_idx):\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "    test_labels = to_cpu_npy(graph.y[targetNode_mask[test_idx]])\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    forward_scores = model(G)[targetNode_mask]\n",
    "\n",
    "    test_scores = forward_scores[test_idx]\n",
    "    test_softmax = F.softmax(test_scores, dim=1)\n",
    "    test_preds = torch.argmax(test_softmax, dim=1)\n",
    "    \n",
    "    test_softmax = to_cpu_npy(test_softmax)\n",
    "    test_preds = to_cpu_npy(test_preds)\n",
    "    test_AUROC = roc_auc_score(test_labels, test_softmax[:,1], average=\"micro\")\n",
    "    test_acc = np.mean(test_preds == test_labels)\n",
    "\n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    train_scores = forward_scores[train_idx]\n",
    "    train_softmax = F.softmax(train_scores, dim=1)\n",
    "    train_preds = torch.argmax(train_softmax, dim=1)\n",
    "    \n",
    "    train_softmax = to_cpu_npy(train_softmax)\n",
    "    train_preds = to_cpu_npy(train_preds)\n",
    "    train_AUROC = roc_auc_score(train_labels, train_softmax[:,1], average=\"micro\")\n",
    "    train_acc = np.mean(train_preds == train_labels)\n",
    "\n",
    "\n",
    "    return {'train_AUROC': train_AUROC, 'train_acc': train_acc, 'test_AUROC': test_AUROC, 'test_acc': test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97f2d5ce-fb4a-47cd-aa1f-72caae0c0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        # First GAT layer\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels[0], heads=num_heads, concat=True)\n",
    "        # Second GAT layer\n",
    "        self.gat2 = GATConv(hidden_channels[0] * num_heads, hidden_channels[1], heads=num_heads, concat=False)\n",
    "        # Third GAT layer\n",
    "        # self.gat3 = GATConv(hidden_channels[1] * num_heads, hidden_channels[2], heads=num_heads, concat=False)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.ff1 = nn.Linear(hidden_channels[1], hidden_channels[1] // 2)\n",
    "        self.ff2 = nn.Linear(hidden_channels[1] // 2, 2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        # Pass through GAT layers\n",
    "        x = torch.relu(self.gat1(x, edge_index, edge_attr))\n",
    "        x = torch.relu(self.gat2(x, edge_index, edge_attr))\n",
    "        # x = torch.relu(self.gat3(x, edge_index, edge_attr))\n",
    "        # Apply dropout and pass through the fully connected layers\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.ff1(x))\n",
    "        x = self.ff2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c3cbad6-dbc0-406e-90df-71b69556a948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 0.48731252551078796, Valid Loss = 0.4492831826210022\n",
      "Epoch 1: Train Loss = 0.48146113753318787, Valid Loss = 0.4704888164997101\n",
      "Epoch 2: Train Loss = 0.44378769397735596, Valid Loss = 0.42149537801742554\n",
      "Epoch 3: Train Loss = 0.3518732488155365, Valid Loss = 0.4540923237800598\n",
      "Epoch 4: Train Loss = 0.4634682238101959, Valid Loss = 0.45065540075302124\n",
      "Epoch 5: Train Loss = 0.4096794128417969, Valid Loss = 0.42113691568374634\n",
      "Epoch 6: Train Loss = 0.4551752209663391, Valid Loss = 0.4474544823169708\n",
      "Epoch 7: Train Loss = 0.39338433742523193, Valid Loss = 0.42444440722465515\n",
      "Epoch 8: Train Loss = 0.4476798474788666, Valid Loss = 0.43534204363822937\n",
      "Epoch 9: Train Loss = 0.47263863682746887, Valid Loss = 0.4376838207244873\n",
      "Epoch 10: Train Loss = 0.41997382044792175, Valid Loss = 0.44391730427742004\n",
      "Epoch 11: Train Loss = 0.4752104878425598, Valid Loss = 0.48312488198280334\n",
      "Epoch 12: Train Loss = 0.4388042390346527, Valid Loss = 0.4019983410835266\n",
      "Epoch 13: Train Loss = 0.4110589027404785, Valid Loss = 0.385581910610199\n",
      "Epoch 14: Train Loss = 0.504130482673645, Valid Loss = 0.4581463932991028\n",
      "Epoch 15: Train Loss = 0.43179234862327576, Valid Loss = 0.4389324486255646\n",
      "Epoch 16: Train Loss = 0.41421303153038025, Valid Loss = 0.48677974939346313\n",
      "Epoch 17: Train Loss = 0.42257848381996155, Valid Loss = 0.4382472336292267\n",
      "Epoch 18: Train Loss = 0.3282058537006378, Valid Loss = 0.44847267866134644\n",
      "Epoch 19: Train Loss = 0.470925897359848, Valid Loss = 0.404305100440979\n"
     ]
    }
   ],
   "source": [
    "num_heads = 4\n",
    "learning_rate = 0.001\n",
    "max_epoch = 20\n",
    "loss = nn.CrossEntropyLoss()\n",
    "hidden_channels=[6, 30]\n",
    "wd = 1e-05\n",
    "\n",
    "gat = GAT(in_channels=6, hidden_channels=hidden_channels, num_heads = num_heads)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, gat.parameters()), lr = learning_rate, weight_decay = wd)\n",
    "\n",
    "train_losses, valid_losses = train_model_classification(gat, loss, train_n_loader, valid_n_loader, max_epoch, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b21ceb94-e353-437e-ba0a-236fdf83ecd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_AUROC': 0.8255024340693489,\n",
       " 'train_acc': 0.7594319445632646,\n",
       " 'test_AUROC': 0.8338861856766094,\n",
       " 'test_acc': 0.7588822355289421}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = eval_model_classification(gat, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "693b1018-a3da-4fd4-8083-fd621ee00344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[279606, 6], edge_index=[2, 3906914], edge_attr=[3906914], y=[279606])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a7d21e-8f79-4496-a75b-9073aa4c631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors at hop 1: tensor([ 1, 11, 11,  ...,  0,  0,  0])\n",
      "Neighbors at hop 2: tensor([ 1, 11, 11,  ...,  0,  0,  0])\n",
      "Neighbors at hop 3: tensor([ 1, 11, 11,  ...,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "def get_neighbors_at_hops(edge_index, num_nodes, max_hops=3):\n",
    "    # Initialize a list to store the number of neighbors at each hop for each node\n",
    "    neighbors_per_hop = {hop: torch.zeros(num_nodes, dtype=torch.long) for hop in range(max_hops)}\n",
    "\n",
    "    # Create a graph with edge_index\n",
    "    edge_list = edge_index.t().contiguous()\n",
    "\n",
    "    for hop in range(max_hops):\n",
    "        # Initialize a set of nodes to start from\n",
    "        visited_nodes = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        \n",
    "        # Start from all nodes and find their neighbors\n",
    "        for node in range(num_nodes):\n",
    "            if not visited_nodes[node]:\n",
    "                neighbors = set()\n",
    "                # Find neighbors at current hop\n",
    "                neighbors = set(edge_list[edge_list[:, 0] == node, 1].tolist())\n",
    "                neighbors_per_hop[hop][node] = len(neighbors)\n",
    "                \n",
    "                visited_nodes[node] = True\n",
    "                for neighbor in neighbors:\n",
    "                    visited_nodes[neighbor] = True\n",
    "    return neighbors_per_hop\n",
    "\n",
    "# Example usage\n",
    "num_nodes = 279606  # Number of nodes\n",
    "max_hops = 3  # Maximum number of hops to explore\n",
    "edge_index = G.edge_index  # Assuming G is your graph object\n",
    "neighbors_per_hop = get_neighbors_at_hops(edge_index, num_nodes, max_hops)\n",
    "\n",
    "# Print the number of neighbors per hop for each node\n",
    "for hop in range(max_hops):\n",
    "    print(f\"Neighbors at hop {hop + 1}: {neighbors_per_hop[hop]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f82f9b9a-ad6a-449a-90b3-cfc8bfedcdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7335)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(neighbors_per_hop[0].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2af0d72-e6a8-4e4b-8d5f-e6259d2f407a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  0,  4,  ...,  0,  0,  0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors_per_hop[0][targetNode_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12021084-2239-43a5-80d6-dbaa23aa147f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     3,      6,     36,  ..., 279593, 279599, 279604])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetNode_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93b9ed26-addf-411d-a316-fa8fca9e4a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,      1,      1,  ..., 279605, 279605, 279605],\n",
       "        [  8765,     24,     67,  ..., 279595, 279598, 279599]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e4de7d9-1cb1-49ad-8488-4398a4a05752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[279606, 6], edge_index=[2, 3906914], edge_attr=[3906914], y=[279606])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6dafef2e-5544-4a49-9f8d-b417d093d18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[     0,      1,      1,  ..., 279595, 279598, 279599],\n",
      "                       [  8765,     24,     67,  ..., 279605, 279605, 279605]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "       device='cuda:0', size=(279606, 279606), nnz=7813828,\n",
      "       layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming G is your graph with edge_index\n",
    "edge_index = G.edge_index  # (2, num_edges)\n",
    "device = edge_index.device  # Get the device of edge_index (GPU or CPU)\n",
    "\n",
    "num_nodes = 279606  # Number of nodes in your graph\n",
    "\n",
    "# Create a sparse adjacency matrix from edge_index, ensuring both are on the same device\n",
    "edge_values = torch.ones(edge_index.size(1), device=device)  # Edge values tensor on the same device\n",
    "adj_matrix = torch.sparse_coo_tensor(\n",
    "    edge_index,  # The (source, target) pairs of edges\n",
    "    edge_values,  # The values of the edges (1 for each edge)\n",
    "    (num_nodes, num_nodes),  # The shape of the matrix\n",
    "    device=device  # Ensure the adjacency matrix is created on the same device\n",
    ")\n",
    "\n",
    "# Convert to dense format (if needed)\n",
    "# dense_adj_matrix = adj_matrix.to_dense()\n",
    "\n",
    "# If the graph is undirected, symmetrize the adjacency matrix\n",
    "adj_matrix = adj_matrix + adj_matrix.t()\n",
    "\n",
    "# Print the adjacency matrix (for small graphs; use only if the graph is small to avoid memory issues)\n",
    "print(adj_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d40aa3-c034-4484-b066-4831d4926151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6082c-a490-4dda-bcdb-460ae2754b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
