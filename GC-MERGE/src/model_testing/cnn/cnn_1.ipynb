{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87966d7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msage_conv_cat_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SAGEConvCat\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_cpu_npy\u001b[39m(x):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/private/GC-MERGE/src/sage_conv_cat_.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_sparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseTensor, matmul\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessagePassing\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSAGEConvCat\u001b[39;00m(MessagePassing):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_sparse'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve, auc\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from sage_conv_cat_ import SAGEConvCat\n",
    "\n",
    "def to_cpu_npy(x):\n",
    "    return x.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "853599ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_classification(nn.Module):\n",
    "\n",
    "    def __init__(self, num_feat, num_conv_layers, conv_layer_sizes, num_lin_layers, lin_hidden_sizes, num_classes):\n",
    "        '''\n",
    "        Defines regression model class\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_feat [int]: Feature dimension (int)\n",
    "        num_conv_layers [int]: Number of convolutional layers (1, 2, or 3)\n",
    "        conv_layer_sizes [list]: Embedding size of convolutional layers \n",
    "        num_lin_layers [int]: Number of linear layers (1, 2, or 3)\n",
    "        lin_hidden_sizes [list]: Embedding size of hidden linear layers\n",
    "        num_classes [int]: Size of predicted output tensor for batch size of N, \n",
    "            i.e. N x num_classes(=1)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        '''\n",
    "        \n",
    "        super(CNN_classification, self).__init__()\n",
    "        \n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_lin_layers = num_lin_layers\n",
    "        self.dropout = 0.5\n",
    "    \n",
    "        # Define convolutional layers\n",
    "        if self.num_conv_layers >= 1:\n",
    "            self.conv1 = nn.Conv1d(num_feat, conv_layer_sizes[0], kernel_size=3)\n",
    "        if self.num_conv_layers >= 2:\n",
    "            self.conv2 = nn.Conv1d(conv_layer_sizes[0], conv_layer_sizes[1], kernel_size=3)\n",
    "        if self.num_conv_layers >= 3:\n",
    "            self.conv3 = nn.Conv1d(conv_layer_sizes[1], conv_layer_sizes[2], kernel_size=3)\n",
    "        \n",
    "        # Define linear layers\n",
    "        if self.num_lin_layers >= 1:\n",
    "            self.lin1 = nn.Linear(lin_hidden_sizes[0], lin_hidden_sizes[1])\n",
    "        if self.num_lin_layers >= 2:\n",
    "            self.lin2 = nn.Linear(lin_hidden_sizes[1], lin_hidden_sizes[2])\n",
    "        if self.num_lin_layers == 3:\n",
    "            self.lin3 = nn.Linear(lin_hidden_sizes[2], lin_hidden_sizes[3])\n",
    "            \n",
    "        self.loss_calc = nn.CrossEntropyLoss()\n",
    "        self.torch_softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        \n",
    "    def forward(self, x, train_status=False):\n",
    "        '''\n",
    "        Forward function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x [tensor]: Node features\n",
    "        edge_index [tensor]: Subgraph mask\n",
    "        train_status [bool]: optional, set to True for dropout\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        scores [tensor]: Predicted expression levels\n",
    "        '''\n",
    "\n",
    "        ### Graph convolution module\n",
    "        if self.num_conv_layers == 1:\n",
    "            h = self.conv1(x, edge_index)\n",
    "            h = torch.relu(h)\n",
    "        elif self.num_conv_layers == 2:\n",
    "            h = self.conv1(x, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            h = self.conv2(h, edge_index)\n",
    "            h = torch.relu(h)\n",
    "        elif self.num_conv_layers == 3:\n",
    "            h = self.conv1(x, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            h = self.conv2(h, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            h = self.conv3(h, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            \n",
    "        h = F.dropout(h, p = self.dropout_value, training=train_status)\n",
    "\n",
    "        ### Linear module\n",
    "        if self.num_lin_layers == 1:\n",
    "            scores = self.lin1(h)\n",
    "        elif self.num_lin_layers == 2:\n",
    "            scores = self.lin1(h)\n",
    "            scores = torch.relu(scores)\n",
    "            scores = self.lin2(scores)\n",
    "        elif self.num_lin_layers == 3:\n",
    "            scores = self.lin1(h)\n",
    "            scores = torch.relu(scores)\n",
    "            scores = self.lin2(scores)\n",
    "            scores = torch.relu(scores)\n",
    "            scores = self.lin3(scores)\n",
    "        \n",
    "        return scores\n",
    "\n",
    "    \n",
    "    def loss(self, scores, targets):\n",
    "        '''\n",
    "        Calculates mean squared error loss\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        scores [tensor]: Predicted scores from forward function\n",
    "        targets [tensor]: Target scores \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mse [tensor]: Mean squared error loss\n",
    "\n",
    "        '''\n",
    "        \n",
    "        mse = self.loss_calc(scores, targets)\n",
    "\n",
    "        return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34c14a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_cnn_classification(model, X, y, max_epoch, learning_rate, train_idx, valid_idx, optimizer):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    optimizer = optimizer\n",
    "\n",
    "    train_labels = y[train_idx].cpu().numpy()\n",
    "    valid_labels = y[valid_idx].cpu().numpy()\n",
    "\n",
    "    train_loss_list = []\n",
    "    train_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    print('\\n')\n",
    "    for e in range(max_epoch):\n",
    "        if e % 100 == 0:\n",
    "            print(f\"Epoch {e} out of {max_epoch}\")\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        forward_scores = model(X, train_status)\n",
    "        train_scores = forward_scores[train_idx]\n",
    "        train_loss = model.loss(train_scores, y[train_idx])\n",
    "        train_softmax, _ = model.calc_softmax_pred(train_scores)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss = model.loss(valid_scores, y[valid_idx])\n",
    "        valid_softmax, _ = model.calc_softmax_pred(valid_scores)\n",
    "\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        train_softmax = train_softmax.cpu().detach().numpy()\n",
    "        train_AUROC = roc_auc_score(train_labels, train_softmax[:, 1], average=\"micro\")\n",
    "        \n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        valid_softmax = valid_softmax.cpu().detach().numpy()\n",
    "        valid_AUROC = roc_auc_score(valid_labels, valid_softmax[:, 1], average=\"micro\")\n",
    "\n",
    "        train_AUROC_vec[e] = train_AUROC\n",
    "        valid_AUROC_vec[e] = valid_AUROC\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13230940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_cnn(model, X, y, idx):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X[idx])\n",
    "        if isinstance(model, CNN_classification):\n",
    "            softmax, preds = model.calc_softmax_pred(outputs)\n",
    "            preds = preds.cpu().numpy()\n",
    "            softmax = softmax.cpu().numpy()\n",
    "            labels = y[idx].cpu().numpy()\n",
    "            AUROC = roc_auc_score(labels, softmax[:, 1])\n",
    "            precision, recall, _ = precision_recall_curve(labels, softmax[:, 1])\n",
    "            AUPR = auc(recall, precision)\n",
    "            return AUROC, AUPR, preds, labels\n",
    "        else:\n",
    "            preds = outputs.cpu().numpy()\n",
    "            labels = y[idx].cpu().numpy()\n",
    "            pearson = pearsonr(preds, labels)[0]\n",
    "            return pearson, preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a435b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line = 'E116'\n",
    "regression_flag = 0\n",
    "max_epoch = 1000\n",
    "learning_rate = 1e-4\n",
    "num_graph_conv_layers = 2\n",
    "graph_conv_embed_size = 256\n",
    "num_lin_layers = 3\n",
    "lin_hidden_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80aebae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Model date and time:\n",
      "2024-11-01-at-10-57-20 \n",
      "\n",
      "\n",
      "Cell line: E116\n",
      "Task: Classification\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.0001\n",
      "Number of graph convolutional layers: 2\n",
      "Graph convolutional embedding size: 256\n",
      "Number of linear layers: 3\n",
      "Linear hidden layer size: 256\n",
      "\n",
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([6, 6, 3])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([256, 6, 3])\n",
      "conv2.bias \t torch.Size([256])\n",
      "lin1.weight \t torch.Size([256, 256])\n",
      "lin1.bias \t torch.Size([256])\n",
      "lin2.weight \t torch.Size([256, 256])\n",
      "lin2.bias \t torch.Size([256])\n",
      "lin3.weight \t torch.Size([2, 256])\n",
      "lin3.bias \t torch.Size([2])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'edge_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1924/2056369447.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;31m### Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mtrain_loss_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_AUROC_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_AUROC_vec\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mtrain_model_cnn_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m### Evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1924/309715360.py\u001b[0m in \u001b[0;36mtrain_model_cnn_classification\u001b[0;34m(model, X, y, max_epoch, learning_rate, train_idx, valid_idx, optimizer)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mforward_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1924/935229385.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, train_status)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_conv_layers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'edge_index' is not defined"
     ]
    }
   ],
   "source": [
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)\n",
    "\n",
    "if regression_flag == 0:\n",
    "    num_classes = 2\n",
    "    task = 'Classification'\n",
    "else:\n",
    "    num_classes = 1\n",
    "    task = 'Regression'\n",
    "\n",
    "\n",
    "###Initialize start time\n",
    "start_time = time.time()\n",
    "\n",
    "today = date.today()\n",
    "mdy = today.strftime(\"%Y-%m-%d\")\n",
    "clock = datetime.now()\n",
    "hms = clock.strftime(\"%H-%M-%S\")\n",
    "hm = clock.strftime(\"%Hh-%Mm\")\n",
    "hm_colon = clock.strftime(\"%H:%M\")\n",
    "date_and_time = mdy + '-at-' + hms\n",
    "\n",
    "\n",
    "###Test for GPU availability\n",
    "cuda_flag = torch.cuda.is_available()\n",
    "if cuda_flag:  \n",
    "    dev = \"cuda\" \n",
    "else:\n",
    "    dev = \"cpu\"  \n",
    "print(dev) \n",
    "device = torch.device(dev)  \n",
    "\n",
    "\n",
    "###Load input files\n",
    "base_path = os.getcwd()\n",
    "save_dir = os.path.join(base_path, 'data', cell_line, 'saved_runs')\n",
    "hic_sparse_mat_file = os.path.join(base_path, 'data', cell_line, 'hic_sparse.npz')\n",
    "np_nodes_lab_genes_file = os.path.join(base_path, 'data',  cell_line, \\\n",
    "    'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')\n",
    "np_hmods_norm_all_file = os.path.join(base_path, 'data', cell_line, \\\n",
    "    'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "df_genes_file = os.path.join(base_path, 'data', cell_line, 'df_genes_reg' + str(regression_flag) + '.pkl')\n",
    "df_genes = pd.read_pickle(df_genes_file)\n",
    "    \n",
    "###Print model specifications\n",
    "print('Model date and time:')\n",
    "print(date_and_time, '\\n\\n')\n",
    "print('Cell line:', cell_line)\n",
    "print('Task:', task)\n",
    "print('ChIP-seq resolution:', str(chip_res))\n",
    "print('\\n')\n",
    "print('Training set: 70%')\n",
    "print('Validation set: 15%')\n",
    "print('Testing set: 15%')\n",
    "print('\\n')\n",
    "print('Model hyperparameters: ')\n",
    "print('Number of epochs:', max_epoch)\n",
    "print('Learning rate:', learning_rate)\n",
    "print('Number of graph convolutional layers:', str(num_graph_conv_layers))\n",
    "print('Graph convolutional embedding size:', graph_conv_embed_size)\n",
    "print('Number of linear layers:', str(num_lin_layers))\n",
    "print('Linear hidden layer size:', lin_hidden_size)\n",
    "\n",
    "\n",
    "###Define model inputs\n",
    "mat = load_npz(hic_sparse_mat_file)\n",
    "allNodes_hms = np.load(np_hmods_norm_all_file)\n",
    "hms = allNodes_hms[:, 1:] #only includes features, not node ids\n",
    "X = torch.tensor(hms).float().reshape(-1, num_feat) \n",
    "allNodes = allNodes_hms[:, 0].astype(int)\n",
    "geneNodes_labs = np.load(np_nodes_lab_genes_file)\n",
    "\n",
    "geneNodes = geneNodes_labs[:, -2].astype(int)\n",
    "allLabs = -1*np.ones(np.shape(allNodes))\n",
    "\n",
    "targetNode_mask = torch.tensor(geneNodes).long()\n",
    "\n",
    "if regression_flag == 0:\n",
    "    geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "    allLabs[geneNodes] = geneLabs\n",
    "    Y = torch.tensor(allLabs).long()\n",
    "else:\n",
    "    geneLabs = geneNodes_labs[:, -1].astype(float)\n",
    "    allLabs[geneNodes] = geneLabs\n",
    "    Y = torch.tensor(allLabs).float()\n",
    "\n",
    "extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "data = torch_geometric.data.Data(edge_index = extract[0], edge_attr = extract[1], x = X, y = Y)\n",
    "G = data\n",
    "\n",
    "\n",
    "###Define convolutional and linear layer input/output sizes\n",
    "graph_conv_layer_sizes = [num_feat] + \\\n",
    "    [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "          for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "        \n",
    "lin_hidden_sizes = [graph_conv_layer_sizes[-1]] + \\\n",
    "    [int(max(lin_hidden_size, num_classes)) \\\n",
    "          for i in np.arange(1, num_lin_layers, 1)] + [num_classes]\n",
    "\n",
    "\n",
    "###Randomize node order and split into 70%/15%/15% training/validation/test sets\n",
    "pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "\n",
    "fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "train_idx = pred_idx_shuff[:fin_train]\n",
    "valid_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "test_idx = pred_idx_shuff[fin_valid:]\n",
    "\n",
    "train_gene_ID = targetNode_mask[train_idx].numpy()\n",
    "valid_gene_ID = targetNode_mask[valid_idx].numpy()\n",
    "test_gene_ID = targetNode_mask[test_idx].numpy()\n",
    "\n",
    "\n",
    "###Instantiate neural network model, choose optimizer, and print model parameters\n",
    "if regression_flag == 0:\n",
    "    model = CNN_classification(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, lin_hidden_sizes, num_classes)\n",
    "else:\n",
    "    model = CNN_regression(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, lin_hidden_sizes, num_classes)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), \n",
    "                            lr = learning_rate)\n",
    "\n",
    "print(\"\\n\"+\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "\n",
    "### For classification:\n",
    "if regression_flag == 0:\n",
    "    \n",
    "    ### Train model\n",
    "    train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec = \\\n",
    "        train_model_cnn_classification(model, X, Y, max_epoch, learning_rate, train_idx, valid_idx, optimizer)\n",
    "    \n",
    "    ### Evaluate model\n",
    "    test_AUROC, test_AUPR, test_pred, test_labels, train_AUPR, train_pred, train_labels, \\\n",
    "            valid_AUPR, valid_pred, valid_labels = \\\n",
    "                eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "    \n",
    "    ### Save metrics and node predictions\n",
    "    train_metrics = [train_gene_ID, train_pred, train_labels, train_AUROC_vec, train_AUPR, train_loss_vec]\n",
    "    np.save(os.path.join(save_dir, 'model_' + date_and_time + '_train_metrics'  + '.npy'), np.asarray(train_metrics, dtype=object))\n",
    "    \n",
    "    valid_metrics = [valid_gene_ID, valid_pred, valid_labels, valid_AUROC_vec, valid_AUPR, valid_loss_vec]\n",
    "    np.save(os.path.join(save_dir, 'model_' + date_and_time + '_valid_metrics'  + '.npy'), np.asarray(valid_metrics, dtype=object))\n",
    "    \n",
    "    test_metrics = [test_gene_ID, test_pred, test_labels, test_AUROC, test_AUPR, ['na']]\n",
    "    np.save(os.path.join(save_dir, 'model_' + date_and_time + '_test_metrics'  + '.npy'), np.asarray(test_metrics, dtype=object))\n",
    "    \n",
    "    dataset_list = [train_metrics, valid_metrics, test_metrics]\n",
    "    df_full_metrics = pd.DataFrame(columns=['Dataset','Node ID','True Label','Predicted Label','Classification'])\n",
    "    \n",
    "    for d in np.arange(len(dataset_list)):\n",
    "        dataset_metrics = dataset_list[d]\n",
    "        partial_metrics = pd.DataFrame()\n",
    "    \n",
    "        partial_metrics['Node ID'] = dataset_metrics[0]\n",
    "        partial_metrics['True Label'] = dataset_metrics[2]\n",
    "        partial_metrics['Predicted Label'] = dataset_metrics[1]\n",
    "        partial_metrics['Classification'] = dataset_metrics[1]*1 + dataset_metrics[2]*2\n",
    "        partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
    "        partial_metrics['Classification'].replace(to_replace=1, value='FP', inplace=True)\n",
    "        partial_metrics['Classification'].replace(to_replace=2, value='FN', inplace=True)\n",
    "        partial_metrics['Classification'].replace(to_replace=3, value='TP', inplace=True)\n",
    "        \n",
    "        if d == 0:\n",
    "            partial_metrics['Dataset'] = 'Training'\n",
    "        elif d == 1:\n",
    "            partial_metrics['Dataset'] = 'Validation'\n",
    "        elif d == 2:\n",
    "            partial_metrics['Dataset'] = 'Testing'\n",
    "    \n",
    "        df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n",
    "    \n",
    "    df_gene_names = df_genes.iloc[:,:3]\n",
    "    df_gene_names = df_gene_names.rename(columns={\"gene_catalog_name\": \"ENSEMBL_ID\", \"abbrev\": \"Abbreviation\",\n",
    "                                  \"hic_node_id\" : 'Node ID'})\n",
    "    df_full_metrics = pd.merge(df_full_metrics, df_gene_names, how='inner', on='Node ID')\n",
    "    df_full_metrics = df_full_metrics[df_full_metrics.columns[[0,1,5,6,2,3,4]]]\n",
    "\n",
    "### For regression:\n",
    "elif regression_flag == 1:\n",
    "\n",
    "    ### Train model\n",
    "    train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec = \\\n",
    "        train_model_regression(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "    \n",
    "    ### Evaluate model\n",
    "    test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "            valid_pearson, valid_pred, valid_labels = \\\n",
    "                eval_model_regression(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "    \n",
    "    ### Save metrics and node predictions\n",
    "    train_metrics = [train_gene_ID, train_pred, train_labels, train_pearson_vec, train_loss_vec]\n",
    "    np.save(os.path.join(save_dir, 'model_' + date_and_time + '_train_metrics'  + '.npy'), np.asarray(train_metrics, dtype=object))\n",
    "    \n",
    "    valid_metrics = [valid_gene_ID, valid_pred, valid_labels, valid_pearson_vec, valid_loss_vec]\n",
    "    np.save(os.path.join(save_dir, 'model_' + date_and_time + '_valid_metrics'  + '.npy'), np.asarray(valid_metrics, dtype=object))\n",
    "    \n",
    "    test_metrics = [test_gene_ID, test_pred, test_labels, test_pearson, ['na']]\n",
    "    np.save(os.path.join(save_dir, 'model_' + date_and_time + '_test_metrics'  + '.npy'), np.asarray(test_metrics, dtype=object))\n",
    "    \n",
    "    dataset_list = [train_metrics, valid_metrics, test_metrics]\n",
    "    df_full_metrics = pd.DataFrame(columns=['Dataset','Node ID','True Label','Predicted Label'])\n",
    "    \n",
    "    for d in np.arange(len(dataset_list)):\n",
    "        dataset_metrics = dataset_list[d]\n",
    "        partial_metrics = pd.DataFrame()\n",
    "    \n",
    "        partial_metrics['Node ID'] = dataset_metrics[0]\n",
    "        partial_metrics['True Label'] = dataset_metrics[2]\n",
    "        partial_metrics['Predicted Label'] = dataset_metrics[1]\n",
    "        \n",
    "        if d == 0:\n",
    "            partial_metrics['Dataset'] = 'Training'\n",
    "        elif d == 1:\n",
    "            partial_metrics['Dataset'] = 'Validation'\n",
    "        elif d == 2:\n",
    "            partial_metrics['Dataset'] = 'Testing'\n",
    "    \n",
    "        df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n",
    "    \n",
    "    df_gene_names = df_genes.iloc[:,:3]\n",
    "    df_gene_names = df_gene_names.rename(columns={\"gene_catalog_name\": \"ENSEMBL_ID\", \"abbrev\": \"Abbreviation\",\n",
    "                                  \"hic_node_id\" : 'Node ID'})\n",
    "    df_full_metrics = pd.merge(df_full_metrics, df_gene_names, how='inner', on='Node ID')\n",
    "    df_full_metrics = df_full_metrics[df_full_metrics.columns[[0,1,4,5,2,3]]]\n",
    "\n",
    "\n",
    "### Print elapsed time and performance\n",
    "elapsed = (time.time() - start_time)\n",
    "elapsed_h = int(elapsed//3600)\n",
    "elapsed_m = int((elapsed - elapsed_h*3600)//60)\n",
    "elapsed_s = int(elapsed - elapsed_h*3600 - elapsed_m*60)\n",
    "print('Elapsed time: {0:02d}:{1:02d}:{2:02d}'.format(elapsed_h, elapsed_m, elapsed_s))\n",
    "\n",
    "print('\\nPerformance:')\n",
    "if regression_flag == 0:\n",
    "    print('Test AUROC:', test_AUROC, '\\n')\n",
    "    print('Test AUPR:', test_AUPR, '\\n\\n')\n",
    "elif regression_flag == 1:\n",
    "    print('Test pearson:', test_pearson, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74dade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
